{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part9\\metadata.json\", 'r') as f:\n",
    "    colony_pic_metadata_json = f.read()\n",
    "    colony_pic_metadata = json.loads(colony_pic_metadata_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deep_find_dict(dict_: dict, key, default_val=-1) -> list:\n",
    "    \"\"\"\n",
    "    Finds and returns the associated value of the key in a nested dictionary.\n",
    "    If a key appears multiple times in a nested dictionary, it returns the first value.\n",
    "    If the key does not appear in the nested dictionary, returns default_val\n",
    "    Inputs:\n",
    "        dict_: Target dictionary\n",
    "        key: Target key name\n",
    "        default_val(default = -1): value returned if key does not appear in the nested dictionary\n",
    "    Returns:\n",
    "        res: value of first appearance of associated key in the given dictionary\n",
    "    \"\"\"\n",
    "    if key in dict_.keys():\n",
    "        return dict_[key]\n",
    "    else:\n",
    "        for int_key, val in dict_.items():\n",
    "            if isinstance(dict_[int_key], dict):\n",
    "                res = deep_find_dict(dict_[int_key], key)\n",
    "                if res is not None: return res\n",
    "    return default_val\n",
    "\n",
    "def extract_paths_with_colonies(json_: dict, min_colonies: int=1, max_colonies: int=-1, path: str='Relative Path'):\n",
    "    \"\"\"\n",
    "    Returns relative file paths of all files with non-zero colony counts\n",
    "    Inputs:\n",
    "        json_: JSON file containing the metadata of the plate photographs.\n",
    "        min_colonies: minimum number of colonies desired on returned images.\n",
    "        max_colonies: maximum number of colonies desired on returned images.\n",
    "    Returns:\n",
    "        img_paths: list of the relative file paths of images containing between min_colonies and max_colonies\n",
    "                   number of colonies.\n",
    "    \"\"\"\n",
    "    img_paths = list()\n",
    "    if max_colonies == -1:\n",
    "        max_colonies = np.Inf\n",
    "    for key, val in json_.items():\n",
    "        colony_count = deep_find_dict(val, 'Bacterial Load Estimation')\n",
    "        if (colony_count >= min_colonies) and (colony_count <= max_colonies):\n",
    "            img_paths.append((colony_count, val['Relative Path']))\n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = extract_paths_with_colonies(colony_pic_metadata['images_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract zipfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_files = glob.glob(\"F:\\Colonies_Data\\*.zip\")\n",
    "zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part20.zip.\n",
      "Removed F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part20.zip.\n",
      "Extracting F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part19.zip.\n",
      "Removed F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part19.zip.\n"
     ]
    }
   ],
   "source": [
    "for file_loc in zip_files:\n",
    "    with zipfile.ZipFile(file_loc, 'r') as zf:\n",
    "        print(f\"Extracting {file_loc}.\")\n",
    "        zf.extractall(path=\"F:\\Colonies_Data\\\\\")\n",
    "    os.remove(file_loc)\n",
    "    print(f\"Removed {file_loc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part9\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part3\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part4\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part1\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part6\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part5\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part2\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part7\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part12\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part8\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part11\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part10\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part13\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part14\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part20\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part19\\\\metadata.json']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('F:\\Colonies_Data\\*\\metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-GPU)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
