{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part9\\metadata.json\", 'r') as f:\n",
    "    colony_pic_metadata_json = f.read()\n",
    "    colony_pic_metadata = json.loads(colony_pic_metadata_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deep_find_dict(dict_: dict, key, default_val=-1) -> list:\n",
    "    \"\"\"\n",
    "    Finds and returns the associated value of the key in a nested dictionary.\n",
    "    If a key appears multiple times in a nested dictionary, it returns the first value.\n",
    "    If the key does not appear in the nested dictionary, returns default_val\n",
    "    Inputs:\n",
    "        dict_: Target dictionary\n",
    "        key: Target key name\n",
    "        default_val(default = -1): value returned if key does not appear in the nested dictionary\n",
    "    Returns:\n",
    "        res: value of first appearance of associated key in the given dictionary\n",
    "    \"\"\"\n",
    "    if key in dict_.keys():\n",
    "        return dict_[key]\n",
    "    else:\n",
    "        for int_key, val in dict_.items():\n",
    "            if isinstance(dict_[int_key], dict):\n",
    "                res = deep_find_dict(dict_[int_key], key)\n",
    "                if res is not None: return res\n",
    "    return default_val\n",
    "\n",
    "def extract_paths_with_colonies(json_: dict, min_colonies: int=1, max_colonies: int=-1, path: str='Relative Path'):\n",
    "    \"\"\"\n",
    "    Returns relative file paths of all files with non-zero colony counts\n",
    "    Inputs:\n",
    "        json_: JSON file containing the metadata of the plate photographs.\n",
    "        min_colonies: minimum number of colonies desired on returned images.\n",
    "        max_colonies: maximum number of colonies desired on returned images.\n",
    "    Returns:\n",
    "        img_paths: list of tuples of the colony count and the relative file paths of images containing between \n",
    "            min_colonies and max_colonies number of colonies.\n",
    "    \"\"\"\n",
    "    img_paths = list()\n",
    "    if max_colonies == -1:\n",
    "        max_colonies = np.Inf\n",
    "    for key, val in json_.items():\n",
    "        colony_count = deep_find_dict(val, 'Bacterial Load Estimation')\n",
    "        if (colony_count >= min_colonies) and (colony_count <= max_colonies):\n",
    "            img_paths.append((colony_count, val['Relative Path']))\n",
    "    return img_paths\n",
    "\n",
    "def flatten(test_list):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/12472338/flattening-a-list-recursively\n",
    "    Recursively flattens a nested listed into a list of non-list elements.\n",
    "    Inputs:\n",
    "        test_list: list to be flattened\n",
    "    Returns:\n",
    "        A flattened version of test_list, containing all the elements contained in test_list and its list elements \n",
    "        flattened.\n",
    "    \"\"\"\n",
    "    if isinstance(test_list, list):\n",
    "        if len(test_list) == 0:\n",
    "            return []\n",
    "        first, rest = test_list[0], test_list[1:]\n",
    "        return flatten(first) + flatten(rest)\n",
    "    else:\n",
    "        return [test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = extract_paths_with_colonies(colony_pic_metadata['images_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract zipfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part18.zip',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part17.zip',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part15.zip',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part16.zip']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_files = glob.glob(\"F:\\Colonies_Data\\*.zip\")\n",
    "zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part18.zip.\n",
      "Removed F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part18.zip.\n",
      "Extracting F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part17.zip.\n",
      "Removed F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part17.zip.\n",
      "Extracting F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part15.zip.\n",
      "Removed F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part15.zip.\n",
      "Extracting F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part16.zip.\n",
      "Removed F:\\Colonies_Data\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part16.zip.\n"
     ]
    }
   ],
   "source": [
    "for file_loc in zip_files:\n",
    "    with zipfile.ZipFile(file_loc, 'r') as zf:\n",
    "        print(f\"Extracting {file_loc}.\")\n",
    "        zf.extractall(path=\"F:\\Colonies_Data\\\\\")\n",
    "    os.remove(file_loc)\n",
    "    print(f\"Removed {file_loc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_metadata = glob.glob('F:\\Colonies_Data\\*\\metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding number of usable images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part9\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part3\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part4\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part1\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part6\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part5\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part2\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part7\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part12\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part8\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part11\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part10\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part13\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part14\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part20\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part19\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part18\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part17\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part15\\\\metadata.json',\n",
       " 'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part16\\\\metadata.json']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_paths = list()\n",
    "for metadata_loc in plate_metadata:\n",
    "    absolute_path = metadata_loc.split(\"\\\\metadata.json\")[0]\n",
    "    with open(metadata_loc, 'r') as f:\n",
    "        colony_pic_metadata_json = f.read()\n",
    "        colony_pic_metadata = json.loads(colony_pic_metadata_json)\n",
    "    img_paths = extract_paths_with_colonies(colony_pic_metadata['images_list'], max_colonies=99 )\n",
    "    full_img_paths = [(path[0], absolute_path + '/' + path[1]) for path in img_paths]\n",
    "    all_img_paths.append(full_img_paths)\n",
    "all_img_paths = flatten(all_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part9/F/T4h_inf/IMG_Niguarda1_127_121_F6_T543.png'),\n",
       " (2,\n",
       "  'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part9/S/T4h_inf/IMG_Niguarda1_1352_710_S54_T962.png'),\n",
       " (6,\n",
       "  'F:\\\\Colonies_Data\\\\MicrobIA_Dataset_only_counted_processed_anonimyzed_part9/F/T4h_inf/IMG_Niguarda1_1421_610_F6_T541.png')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img_paths[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-GPU)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
