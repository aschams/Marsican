{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Check OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import scipy.ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_contrast_brightness(image, alpha, beta):\n",
    "    \"\"\"\n",
    "    https://docs.opencv.org/3.4/d3/dc1/tutorial_basic_linear_transform.html\n",
    "    \"\"\"\n",
    "    new_image = np.zeros(image.shape, image.dtype)\n",
    "    \n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            for c in range(image.shape[2]):\n",
    "                new_image[y,x,c] = np.clip(alpha*image[y,x,c] + beta, 0, 255)\n",
    "    return new_image\n",
    "\n",
    "def gamma_adjustment(img_original, gamma):\n",
    "    \"\"\"\n",
    "    https://docs.opencv.org/3.4/d3/dc1/tutorial_basic_linear_transform.html\n",
    "    \"\"\"\n",
    "    lookUpTable = np.empty((1,256), np.uint8)\n",
    "    for i in range(256):\n",
    "        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "    res = cv2.LUT(img_original, lookUpTable)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'win32' in sys.platform:\n",
    "    ex_filepath = 'F:\\Colonies_Data\\data\\plate 2_24.png'\n",
    "if 'darwin' in sys.platform:\n",
    "    ex_filepath = \"/Volumes/Samsung_T5/Colonies_Data/data/plate 2_24.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find position and radius of the plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[525 461 470]]\n"
     ]
    }
   ],
   "source": [
    "# https://www.pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "ex_filepath = \"/Volumes/Samsung_T5/Segmentation_Data/VC0395_300mOsm_12.JPG\"\n",
    "IMG_SIZE = 1000\n",
    "\n",
    "image = cv2.imread(ex_filepath)\n",
    "image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "output = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, minDist=int(IMG_SIZE/3), dp=2, minRadius=int(IMG_SIZE/3), maxRadius=int(IMG_SIZE/2))\n",
    " \n",
    "    \n",
    "if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "    circle_ = np.round(circles[0, :]).astype(\"int\")\n",
    "    print(circle_)\n",
    "    # loop over the (x, y) coordinates and radius of the circles\n",
    "    x, y, r = circle_[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(ex_filepath).convert(\"RGB\").resize((1000,1000))\n",
    "\n",
    "npImage=np.array(img)\n",
    "image = change_contrast_brightness(npImage, .8, 10)\n",
    "\n",
    "# Create same size alpha layer with circle\n",
    "alpha = Image.new('L', img.size,0)\n",
    "draw = ImageDraw.Draw(alpha)\n",
    "draw.pieslice([x-r, y-r, x+r, y+r],0,360,fill=255)\n",
    "\n",
    "# Convert alpha Image to numpy array\n",
    "npAlpha=np.array(alpha)\n",
    "\n",
    "# Add alpha layer to RGB\n",
    "npImage=np.dstack((image,npAlpha))\n",
    "\n",
    "# Save with alpha\n",
    "Image.fromarray(npImage).save('result.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Small circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[705 933  24]\n",
      " [703 935  24]\n",
      " [699 937  24]\n",
      " ...\n",
      " [199 771  11]\n",
      " [671 941  11]\n",
      " [413 971  11]]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('result.png', cv2.IMREAD_UNCHANGED)\n",
    "image2 = cv2.bitwise_not(image[:,:,:3])\n",
    "output = image2.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, minDist=1, dp=2, minRadius=10, maxRadius=25, param2=37)\n",
    " \n",
    "    \n",
    "if circles is not None:\n",
    "    # convert the (x, y) coordinates and radius of the circles to integers\n",
    "    circle_ = np.round(circles[0, :]).astype(\"int\")\n",
    "    print(circle_)\n",
    "    # loop over the (x, y) coordinates and radius of the circles\n",
    "    for (x, y, r) in circle_:\n",
    "        # draw the circle in the output image, then draw a rectangle\n",
    "        # corresponding to the center of the circle\n",
    "        cv2.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "        cv2.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
    " \n",
    "    # show the output image\n",
    "#     cv2.imshow(\"output\", np.hstack([image2, output]))\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_stdev(arr, radius):\n",
    "    c1 = nd.filters.uniform_filter(arr, radius*2, mode='constant', origin=-radius)\n",
    "    c2 = nd.filters.uniform_filter(arr*arr, radius*2, mode='constant', origin=-radius)\n",
    "    return ((c2 - c1*c1)**.5)[:-radius*2+1,:-radius*2+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 898,  898,  898, ..., 2943, 2943, 2943]), array([2023, 2024, 2025, ..., 1715, 1716, 1717]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(ex_filepath,0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread(\"/Volumes/Samsung_T5/Segmentation_Data/VC0395_300mOsm_12_colony.JPG\",0)\n",
    "img_rgb = cv2.imread(ex_filepath)\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.6\n",
    "loc = np.where( res >= threshold)\n",
    "print(loc)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "\n",
    "cv2.imwrite('res.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = list(zip(*loc[::-1]))\n",
    "matches = sorted(matches, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_locs = []\n",
    "current_loc = matches[0]\n",
    "curr_lim = matches[0]\n",
    "for match in matches:\n",
    "    if ((match[0] < current_loc[0] + w) \n",
    "        and(match[1] < current_loc[1] + h)\n",
    "        and(match[0] >= current_loc[0])\n",
    "        and((match[1] >= current_loc[1] - h) and (match[1] <= current_loc[1] + h))): # Inside curr_loc's box\n",
    "            current_lim = match\n",
    "    else:\n",
    "        unique_locs.append((current_loc, current_lim))\n",
    "        current_loc = match\n",
    "        curr_lim = match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2021, 900), (2032, 908)),\n",
       " ((1282, 1320), (1296, 1323)),\n",
       " ((1718, 1439), (1718, 1440)),\n",
       " ((1662, 1444), (1674, 1447)),\n",
       " ((711, 1539), (719, 1542)),\n",
       " ((1394, 1548), (1416, 1549)),\n",
       " ((1791, 1854), (1810, 1856)),\n",
       " ((785, 2173), (803, 2174)),\n",
       " ((983, 2705), (996, 2715)),\n",
       " ((958, 2797), (982, 2721)),\n",
       " ((1718, 2927), (1723, 2937)),\n",
       " ((1701, 2929), (1716, 2943)),\n",
       " ((1717, 1440), (1716, 2943)),\n",
       " ((1717, 2927), (1717, 2943))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_locs2 = sorted(unique_locs, key=lambda x:x[1][1])\n",
    "unique_locs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((711, 1539), (719, 1542)),\n",
       " ((785, 2173), (803, 2174)),\n",
       " ((958, 2797), (982, 2721)),\n",
       " ((983, 2705), (996, 2715)),\n",
       " ((1282, 1320), (1296, 1323)),\n",
       " ((1394, 1548), (1416, 1549)),\n",
       " ((1662, 1444), (1674, 1447)),\n",
       " ((1701, 2929), (1716, 2943)),\n",
       " ((1717, 1440), (1716, 2943)),\n",
       " ((1717, 2927), (1717, 2943)),\n",
       " ((1718, 1439), (1718, 1440)),\n",
       " ((1718, 2927), (1723, 2937)),\n",
       " ((1791, 1854), (1810, 1856)),\n",
       " ((2021, 900), (2032, 908))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_close(loc1, loc2, w, h):\n",
    "    loc1_f = np.array(loc1[1])\n",
    "    loc2_f = np.array(loc2[1])\n",
    "    diag_of_rect = np.sqrt(w ** 2 + h ** 2)\n",
    "    if np.linalg.norm(loc1_f - loc2_f, 2) < max(2 * w, 2 * h):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_unique_locs = unique_locs.copy()\n",
    "for location1 in true_unique_locs:\n",
    "    for location2 in true_unique_locs:\n",
    "        if (location1 != location2) and is_close(location1, location2, w, h):\n",
    "            true_unique_locs.remove(location2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((711, 1539), (719, 1542)),\n",
       " ((785, 2173), (803, 2174)),\n",
       " ((958, 2797), (982, 2721)),\n",
       " ((1282, 1320), (1296, 1323)),\n",
       " ((1394, 1548), (1416, 1549)),\n",
       " ((1662, 1444), (1674, 1447)),\n",
       " ((1717, 2927), (1717, 2943)),\n",
       " ((1791, 1854), (1810, 1856)),\n",
       " ((2021, 900), (2032, 908))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_unique_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 898,  898,  898, ..., 2943, 2943, 2943]), array([2023, 2024, 2025, ..., 1715, 1716, 1717]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(ex_filepath,0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread(\"/Volumes/Samsung_T5/Segmentation_Data/VC0395_300mOsm_12_colony.JPG\",0)\n",
    "img_rgb = cv2.imread(ex_filepath)\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.6\n",
    "loc = np.where( res >= threshold)\n",
    "print(loc)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "\n",
    "cv2.imwrite('res.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((711, 1539), (719, 1542))\n",
      "((785, 2173), (803, 2174))\n",
      "((958, 2797), (982, 2721))\n",
      "((983, 2705), (996, 2715))\n",
      "((1282, 1320), (1296, 1323))\n",
      "((1394, 1548), (1416, 1549))\n",
      "((1662, 1444), (1674, 1447))\n",
      "((1701, 2929), (1716, 2943))\n",
      "((1717, 1440), (1716, 2943))\n",
      "((1717, 2927), (1717, 2943))\n",
      "((1718, 1439), (1718, 1440))\n",
      "((1718, 2927), (1723, 2937))\n",
      "((1791, 1854), (1810, 1856))\n",
      "((2021, 900), (2032, 908))\n"
     ]
    }
   ],
   "source": [
    "for ul in unique_locs:\n",
    "    print(ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_boxes(locs, w, h):\n",
    "    loc_1 = locs[0]\n",
    "    loc_2 = locs[1]\n",
    "    upper_left = (min(loc_1[0], loc_2[0]), max(loc_1[1], loc_2[1]))\n",
    "    lower_right = (max(loc_1[0], loc_2[0]) + w, max(loc_1[1], loc_2[1]) + h)\n",
    "    return (upper_left, lower_right)\n",
    "\n",
    "def overlap(locs, w, h):\n",
    "    loc_1 = locs[0]\n",
    "    loc_2 = locs[1]\n",
    "    if     \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = cv2.imread(\"/Volumes/Samsung_T5/Segmentation_Data/VC0395_300mOsm_12_colony.JPG\",0)\n",
    "img_rgb = cv2.imread(ex_filepath)\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.55\n",
    "loc = np.where( res >= threshold)\n",
    "for ul in unique_locs:\n",
    "    upper_left, lower_right = find_max_boxes(ul, w, h)\n",
    "#     cv2.rectangle(img_rgb, ul[0], (ul[1][0] + w, ul[1][1] + h), (0,0,255), 2)\n",
    "    cv2.rectangle(img_rgb, upper_left, lower_right, (0,255,0), 2)\n",
    "\n",
    "cv2.imwrite('res.png',img_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((711, 1539), (719, 1542)),\n",
       " ((785, 2173), (803, 2174)),\n",
       " ((958, 2797), (982, 2721)),\n",
       " ((983, 2705), (996, 2715)),\n",
       " ((1282, 1320), (1296, 1323)),\n",
       " ((1394, 1548), (1416, 1549)),\n",
       " ((1662, 1444), (1674, 1447)),\n",
       " ((1701, 2929), (1716, 2943)),\n",
       " ((1717, 1440), (1716, 2943)),\n",
       " ((1717, 2927), (1717, 2943)),\n",
       " ((1718, 1439), (1718, 1440)),\n",
       " ((1718, 2927), (1723, 2937)),\n",
       " ((1791, 1854), (1810, 1856)),\n",
       " ((2021, 900), (2032, 908))]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to merge close colony boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_locs = unique_locs.copy()\n",
    "len(total_locs)\n",
    "locs_to_remove = []\n",
    "all_locs = []\n",
    "for ul_1 in total_locs:\n",
    "    current_close = 0\n",
    "    for ul_2 in total_locs:\n",
    "        if is_close(ul_1, ul_2, w, h) and ul_1 != ul_2:\n",
    "            all_locs.append(find_max_boxes((ul_1[0], ul_2[0]), w, h))\n",
    "            locs_to_remove.append(ul_1)\n",
    "            locs_to_remove.append(ul_2)\n",
    "            current_close += 1\n",
    "    if not current_close:\n",
    "        all_locs.append(find_max_boxes(ul_1, w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((711, 1542), (820, 1633)),\n",
       " ((785, 2174), (904, 2265)),\n",
       " ((958, 2797), (1084, 2888)),\n",
       " ((1282, 1323), (1397, 1414)),\n",
       " ((1394, 1549), (1517, 1640)),\n",
       " ((1662, 1444), (1819, 1535)),\n",
       " ((1701, 2929), (1818, 3020)),\n",
       " ((1701, 2929), (1819, 3020)),\n",
       " ((1717, 2927), (1818, 3018)),\n",
       " ((1717, 2927), (1819, 3018)),\n",
       " ((1791, 1856), (1911, 1947)),\n",
       " ((2021, 908), (2133, 999))}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_locs = set(all_locs)\n",
    "all_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = cv2.imread(\"/Volumes/Samsung_T5/Segmentation_Data/VC0395_300mOsm_12_colony.JPG\",0)\n",
    "img_rgb = cv2.imread(ex_filepath)\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.55\n",
    "loc = np.where( res >= threshold)\n",
    "for ul in all_locs:\n",
    "    upper_left, lower_right = ul[0], ul[1]\n",
    "#     cv2.rectangle(img_rgb, ul[0], (ul[1][0] + w, ul[1][1] + h), (0,0,255), 2)\n",
    "    cv2.rectangle(img_rgb, upper_left, lower_right, (0,255,0), 2)\n",
    "\n",
    "cv2.imwrite('res2.png',img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
