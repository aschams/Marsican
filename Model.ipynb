{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=30, \n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True)\n",
    "\n",
    "if 'win32' in sys.platform:\n",
    "    data_directory='F:\\\\Segmentation_Data\\\\'\n",
    "    full_training_directory = data_directory + 'Labelled_imgs\\\\stratified_data\\\\training\\\\'\n",
    "    full_validation_directory = data_directory +'Labelled_imgs\\\\stratified_data\\\\validation\\\\'\n",
    "\n",
    "if 'darwin' in sys.platform:\n",
    "    data_directory='/Volumes/Samsung_T5/Segmentation_Data/'\n",
    "    full_training_directory = data_directory + 'Labelled_imgs/stratified_data/training/'\n",
    "    full_validation_directory = data_directory +'Labelled_imgs/stratified_data/validation/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20966 images belonging to 8 classes.\n",
      "Found 8984 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(full_training_directory, \n",
    "                                              target_size=(128, 128), \n",
    "                                              color_mode=\"rgb\", \n",
    "                                              batch_size=batch_size)\n",
    "validation_generator = datagen.flow_from_directory(full_validation_directory,\n",
    "                                                   target_size=(128, 128), \n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=False)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "num_test_samples = 8984\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 19:02:29.079627  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 19:02:29.104561  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 19:02:29.112539  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 19:02:29.136981  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0829 19:02:29.136981  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0829 19:02:31.582565  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0829 19:02:31.623456  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0829 19:02:31.700251  6536 deprecation.py:506] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5,5), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(50, (5,5), activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(100, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(200, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01,\n",
    "                          momentum=0.9,\n",
    "                          decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 1.0679 - acc: 0.6055 - val_loss: 0.7752 - val_acc: 0.7053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x195771bb630>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1, \n",
    "                    steps_per_epoch=1000, \n",
    "                    epochs=1, \n",
    "                    validation_data=validation_generator,\n",
    "                   validation_steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1762 1148  977   18  222   68   46]\n",
      " [ 766   52  162    8  201  121  286]\n",
      " [1101   36    1    0    0    0    1]\n",
      " [ 554   10    3    0    0    0    1]\n",
      " [ 282    4    0    0    0    0    2]\n",
      " [ 300    4    0    0    0    0    0]\n",
      " [ 382    3    2    0    0    0    1]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.34      0.42      0.38      4241\n",
      "  2_colonies       0.04      0.03      0.04      1596\n",
      "  3_colonies       0.00      0.00      0.00      1139\n",
      "  4_colonies       0.00      0.00      0.00       568\n",
      "  5_colonies       0.00      0.00      0.00       288\n",
      "  6_colonies       0.00      0.00      0.00       304\n",
      "     outlier       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.21      8524\n",
      "   macro avg       0.06      0.06      0.06      8524\n",
      "weighted avg       0.18      0.21      0.19      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0_colonies','1_colony', \n",
    "                '2_colonies', '3_colonies',\n",
    "                '4_colonies', '5_colonies', \n",
    "                '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4148   77    4    1    0    1   10]\n",
      " [ 126 1328  128    6    0    3    5]\n",
      " [  34  174  805  116    5    5    0]\n",
      " [  15   12  125  331   48   37    0]\n",
      " [   5    2   11   98   67  105    0]\n",
      " [   7    1    5   22   23  212   34]\n",
      " [  40    7    1    0    0    0  340]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.95      0.98      0.96      4241\n",
      "  2_colonies       0.83      0.83      0.83      1596\n",
      "  3_colonies       0.75      0.71      0.73      1139\n",
      "  4_colonies       0.58      0.58      0.58       568\n",
      "  5_colonies       0.47      0.23      0.31       288\n",
      "  6_colonies       0.58      0.70      0.64       304\n",
      "     outlier       0.87      0.88      0.88       388\n",
      "\n",
      "    accuracy                           0.85      8524\n",
      "   macro avg       0.72      0.70      0.70      8524\n",
      "weighted avg       0.84      0.85      0.84      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 18:06:15.504884 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0822 18:06:15.572340 13624 deprecation.py:323] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 1.2578 - acc: 0.5642 - val_loss: 0.9296 - val_acc: 0.6526\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.9432 - acc: 0.6464 - val_loss: 0.7786 - val_acc: 0.7135\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.8306 - acc: 0.6833 - val_loss: 0.7435 - val_acc: 0.7183\n",
      "Epoch 4/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.7664 - acc: 0.7074 - val_loss: 0.6653 - val_acc: 0.7457\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.7080 - acc: 0.7277 - val_loss: 0.7551 - val_acc: 0.7076\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6670 - acc: 0.7421 - val_loss: 0.6814 - val_acc: 0.7409\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6365 - acc: 0.7516 - val_loss: 0.6727 - val_acc: 0.7340\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6127 - acc: 0.7684 - val_loss: 0.6558 - val_acc: 0.7494\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.5869 - acc: 0.7767 - val_loss: 0.5511 - val_acc: 0.7965\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5694 - acc: 0.7830 - val_loss: 0.5024 - val_acc: 0.8101\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5670 - acc: 0.7850 - val_loss: 0.4888 - val_acc: 0.8142\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5426 - acc: 0.7919 - val_loss: 0.4921 - val_acc: 0.8151\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5389 - acc: 0.7926 - val_loss: 0.5276 - val_acc: 0.8032\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.5234 - acc: 0.7994 - val_loss: 0.5711 - val_acc: 0.7770\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5142 - acc: 0.8038 - val_loss: 0.6139 - val_acc: 0.7674\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.5089 - acc: 0.8076 - val_loss: 0.6005 - val_acc: 0.7762\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.5060 - acc: 0.8075 - val_loss: 0.4882 - val_acc: 0.8159\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4955 - acc: 0.8142 - val_loss: 0.4499 - val_acc: 0.8359\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4909 - acc: 0.8129 - val_loss: 0.4423 - val_acc: 0.8323\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4878 - acc: 0.8153 - val_loss: 0.4365 - val_acc: 0.8408\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4818 - acc: 0.8169 - val_loss: 0.5037 - val_acc: 0.8147\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4720 - acc: 0.8187 - val_loss: 0.5092 - val_acc: 0.8063\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4729 - acc: 0.8208 - val_loss: 0.5462 - val_acc: 0.7927\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4657 - acc: 0.8218 - val_loss: 0.5826 - val_acc: 0.7795\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4577 - acc: 0.8266 - val_loss: 0.4413 - val_acc: 0.8363\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4626 - acc: 0.8239 - val_loss: 0.4317 - val_acc: 0.8387\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4604 - acc: 0.8249 - val_loss: 0.4202 - val_acc: 0.8362\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4506 - acc: 0.8270 - val_loss: 0.4130 - val_acc: 0.8452\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4462 - acc: 0.8315 - val_loss: 0.4868 - val_acc: 0.8199\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4460 - acc: 0.8303 - val_loss: 0.4641 - val_acc: 0.8262\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4384 - acc: 0.8310 - val_loss: 0.5118 - val_acc: 0.8096\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4407 - acc: 0.8310 - val_loss: 0.5486 - val_acc: 0.7929\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4389 - acc: 0.8336 - val_loss: 0.4251 - val_acc: 0.8435\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4370 - acc: 0.8346 - val_loss: 0.4151 - val_acc: 0.8486\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4293 - acc: 0.8353 - val_loss: 0.4117 - val_acc: 0.8449\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4279 - acc: 0.8352 - val_loss: 0.4015 - val_acc: 0.8515\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4267 - acc: 0.8378 - val_loss: 0.4353 - val_acc: 0.8398\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4259 - acc: 0.8375 - val_loss: 0.4552 - val_acc: 0.8354\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4250 - acc: 0.8368 - val_loss: 0.5018 - val_acc: 0.8110\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4199 - acc: 0.8412 - val_loss: 0.5436 - val_acc: 0.7898\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4191 - acc: 0.8412 - val_loss: 0.4131 - val_acc: 0.8481\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4164 - acc: 0.8419 - val_loss: 0.4054 - val_acc: 0.8547\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4126 - acc: 0.8418 - val_loss: 0.4168 - val_acc: 0.8505\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4147 - acc: 0.8423 - val_loss: 0.3984 - val_acc: 0.8532\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4094 - acc: 0.8443 - val_loss: 0.4253 - val_acc: 0.8384\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4053 - acc: 0.8462 - val_loss: 0.4370 - val_acc: 0.8416\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4057 - acc: 0.8455 - val_loss: 0.4764 - val_acc: 0.8275\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4004 - acc: 0.8497 - val_loss: 0.5337 - val_acc: 0.8006\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4025 - acc: 0.8482 - val_loss: 0.4254 - val_acc: 0.8464\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4074 - acc: 0.8465 - val_loss: 0.3912 - val_acc: 0.8592\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4012 - acc: 0.8484 - val_loss: 0.3894 - val_acc: 0.8598\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4043 - acc: 0.8475 - val_loss: 0.3776 - val_acc: 0.8614\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3953 - acc: 0.8514 - val_loss: 0.4156 - val_acc: 0.8593\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3944 - acc: 0.8504 - val_loss: 0.4501 - val_acc: 0.8359\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3931 - acc: 0.8506 - val_loss: 0.4760 - val_acc: 0.8272\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3934 - acc: 0.8498 - val_loss: 0.5346 - val_acc: 0.7963\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3907 - acc: 0.8523 - val_loss: 0.4249 - val_acc: 0.8462\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3877 - acc: 0.8521 - val_loss: 0.3922 - val_acc: 0.8581\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3901 - acc: 0.8510 - val_loss: 0.3888 - val_acc: 0.8561\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3817 - acc: 0.8543 - val_loss: 0.3858 - val_acc: 0.8590\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3895 - acc: 0.8532 - val_loss: 0.4134 - val_acc: 0.8449\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3823 - acc: 0.8551 - val_loss: 0.4322 - val_acc: 0.8423\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3870 - acc: 0.8544 - val_loss: 0.4589 - val_acc: 0.8328\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3833 - acc: 0.8559 - val_loss: 0.4986 - val_acc: 0.8151\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3768 - acc: 0.8561 - val_loss: 0.4394 - val_acc: 0.8448\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3830 - acc: 0.8566 - val_loss: 0.3738 - val_acc: 0.8585\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3773 - acc: 0.8555 - val_loss: 0.3816 - val_acc: 0.8591\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3801 - acc: 0.8553 - val_loss: 0.3921 - val_acc: 0.8597\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3751 - acc: 0.8576 - val_loss: 0.3891 - val_acc: 0.8621\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3717 - acc: 0.8572 - val_loss: 0.4311 - val_acc: 0.8439\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3716 - acc: 0.8571 - val_loss: 0.4558 - val_acc: 0.8309\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 123s 123ms/step - loss: 0.3683 - acc: 0.8606 - val_loss: 0.5052 - val_acc: 0.80911s - loss: 0.3682 - \n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3758 - acc: 0.8566 - val_loss: 0.4438 - val_acc: 0.8361\n",
      "Epoch 74/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3701 - acc: 0.8586 - val_loss: 0.3622 - val_acc: 0.8641\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3711 - acc: 0.8594 - val_loss: 0.3739 - val_acc: 0.8609\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 0.3705 - acc: 0.8612 - val_loss: 0.3830 - val_acc: 0.8619\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3667 - acc: 0.8604 - val_loss: 0.3791 - val_acc: 0.8640\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3642 - acc: 0.8629 - val_loss: 0.4151 - val_acc: 0.8526\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3678 - acc: 0.8597 - val_loss: 0.4520 - val_acc: 0.8342\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 124s 124ms/step - loss: 0.3683 - acc: 0.8613 - val_loss: 0.4723 - val_acc: 0.8236\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3653 - acc: 0.8603 - val_loss: 0.4444 - val_acc: 0.8329\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3614 - acc: 0.8604 - val_loss: 0.3844 - val_acc: 0.8674\n",
      "Epoch 83/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3595 - acc: 0.8646 - val_loss: 0.3744 - val_acc: 0.8641\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3639 - acc: 0.8599 - val_loss: 0.3706 - val_acc: 0.8654\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3581 - acc: 0.8647 - val_loss: 0.3705 - val_acc: 0.8672\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3658 - acc: 0.8615 - val_loss: 0.4106 - val_acc: 0.8518\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3607 - acc: 0.8618 - val_loss: 0.4355 - val_acc: 0.8377\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3569 - acc: 0.8626 - val_loss: 0.4698 - val_acc: 0.8265\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3595 - acc: 0.8641 - val_loss: 0.4490 - val_acc: 0.8302\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3560 - acc: 0.8651 - val_loss: 0.3656 - val_acc: 0.8651\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3565 - acc: 0.8631 - val_loss: 0.3743 - val_acc: 0.8690\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3578 - acc: 0.8623 - val_loss: 0.3604 - val_acc: 0.8672\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3539 - acc: 0.8661 - val_loss: 0.3694 - val_acc: 0.8666\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3555 - acc: 0.8659 - val_loss: 0.4090 - val_acc: 0.8535\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3511 - acc: 0.8666 - val_loss: 0.4275 - val_acc: 0.8441\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3555 - acc: 0.8629 - val_loss: 0.4652 - val_acc: 0.8325\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3543 - acc: 0.8640 - val_loss: 0.4573 - val_acc: 0.8288\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3481 - acc: 0.8660 - val_loss: 0.3657 - val_acc: 0.8658\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3520 - acc: 0.8640 - val_loss: 0.3659 - val_acc: 0.8651\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3551 - acc: 0.8641 - val_loss: 0.3592 - val_acc: 0.8678\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3521 - acc: 0.8653 - val_loss: 0.3713 - val_acc: 0.8621\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3467 - acc: 0.8673 - val_loss: 0.3991 - val_acc: 0.8553\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3474 - acc: 0.8664 - val_loss: 0.4398 - val_acc: 0.8430\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3502 - acc: 0.8652 - val_loss: 0.4633 - val_acc: 0.8277\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3445 - acc: 0.8668 - val_loss: 0.4551 - val_acc: 0.8312\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3472 - acc: 0.8655 - val_loss: 0.3818 - val_acc: 0.8685\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3452 - acc: 0.8660 - val_loss: 0.3723 - val_acc: 0.8661\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3516 - acc: 0.8669 - val_loss: 0.3644 - val_acc: 0.8701\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3433 - acc: 0.8669 - val_loss: 0.3760 - val_acc: 0.8593\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3456 - acc: 0.8663 - val_loss: 0.3980 - val_acc: 0.8599\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3460 - acc: 0.8691 - val_loss: 0.4059 - val_acc: 0.8522\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3364 - acc: 0.8716 - val_loss: 0.4504 - val_acc: 0.8350\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3397 - acc: 0.8683 - val_loss: 0.4674 - val_acc: 0.8213\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3415 - acc: 0.8698 - val_loss: 0.3713 - val_acc: 0.8628\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3431 - acc: 0.8664 - val_loss: 0.3676 - val_acc: 0.8660\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3449 - acc: 0.8701 - val_loss: 0.3567 - val_acc: 0.8734\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3438 - acc: 0.8679 - val_loss: 0.3621 - val_acc: 0.8697\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3382 - acc: 0.8705 - val_loss: 0.3776 - val_acc: 0.8612\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3386 - acc: 0.8691 - val_loss: 0.4373 - val_acc: 0.8474\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3360 - acc: 0.8694 - val_loss: 0.4420 - val_acc: 0.8357\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3374 - acc: 0.8713 - val_loss: 0.4796 - val_acc: 0.8228\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3315 - acc: 0.8721 - val_loss: 0.3720 - val_acc: 0.8698\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3390 - acc: 0.8709 - val_loss: 0.3509 - val_acc: 0.8738\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3369 - acc: 0.8719 - val_loss: 0.3568 - val_acc: 0.87410.3375 - - ETA: 0s - loss: 0.3368 - acc: 0.87\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3377 - acc: 0.8713 - val_loss: 0.3557 - val_acc: 0.8697\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3319 - acc: 0.8724 - val_loss: 0.3840 - val_acc: 0.8598\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3372 - acc: 0.8703 - val_loss: 0.4057 - val_acc: 0.8538\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3315 - acc: 0.8726 - val_loss: 0.4306 - val_acc: 0.8414\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3350 - acc: 0.8730 - val_loss: 0.4781 - val_acc: 0.8188\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3294 - acc: 0.8746 - val_loss: 0.3684 - val_acc: 0.8640\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3300 - acc: 0.8740 - val_loss: 0.3661 - val_acc: 0.8721\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3282 - acc: 0.8747 - val_loss: 0.3732 - val_acc: 0.8668\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3294 - acc: 0.8719 - val_loss: 0.3588 - val_acc: 0.8738\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3343 - acc: 0.8729 - val_loss: 0.3732 - val_acc: 0.8658\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3324 - acc: 0.8716 - val_loss: 0.4084 - val_acc: 0.8546\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3296 - acc: 0.8716 - val_loss: 0.4429 - val_acc: 0.8395\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3258 - acc: 0.8740 - val_loss: 0.4779 - val_acc: 0.8218\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3310 - acc: 0.8734 - val_loss: 0.3784 - val_acc: 0.8650\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3274 - acc: 0.8729 - val_loss: 0.3544 - val_acc: 0.8717\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3293 - acc: 0.8747 - val_loss: 0.3632 - val_acc: 0.8738\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3237 - acc: 0.8774 - val_loss: 0.3607 - val_acc: 0.8698\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3302 - acc: 0.8717 - val_loss: 0.3639 - val_acc: 0.8695\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3302 - acc: 0.8719 - val_loss: 0.4058 - val_acc: 0.8501\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3187 - acc: 0.8768 - val_loss: 0.4418 - val_acc: 0.8397\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3250 - acc: 0.8758 - val_loss: 0.4821 - val_acc: 0.8167\n",
      "Epoch 146/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3257 - acc: 0.8726 - val_loss: 0.3917 - val_acc: 0.8606\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3225 - acc: 0.8770 - val_loss: 0.3603 - val_acc: 0.8723\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3246 - acc: 0.8754 - val_loss: 0.3664 - val_acc: 0.8697\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3230 - acc: 0.8753 - val_loss: 0.3736 - val_acc: 0.8620- loss: 0.3220 - ac - ETA: 2s - loss: 0.3223 - acc: 0.875 - ETA: 1s - loss:\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3216 - acc: 0.8765 - val_loss: 0.3747 - val_acc: 0.8687\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "balanced_history = model.fit_generator(train_generator,\n",
    "                                       verbose=1, \n",
    "                                       steps_per_epoch=1000, \n",
    "                                       epochs=100 , \n",
    "                                       validation_data=validation_generator,\n",
    "                                      validation_steps=300,\n",
    "                                      class_weight=class_weights)\n",
    "model.save('balanced_classes.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4187   46    2    0    0    0    6]\n",
      " [ 141 1348   99    5    0    2    1]\n",
      " [  40  194  840   59    4    1    1]\n",
      " [  14   15  165  322   36   16    0]\n",
      " [   5    2   24  114   82   61    0]\n",
      " [   9    1    4   32   47  210    1]\n",
      " [  25    9    1    0    0    0  353]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.95      0.99      0.97      4241\n",
      "  2_colonies       0.83      0.84      0.84      1596\n",
      "  3_colonies       0.74      0.74      0.74      1139\n",
      "  4_colonies       0.61      0.57      0.59       568\n",
      "  5_colonies       0.49      0.28      0.36       288\n",
      "  6_colonies       0.72      0.69      0.71       304\n",
      "     outlier       0.98      0.91      0.94       388\n",
      "\n",
      "    accuracy                           0.86      8524\n",
      "   macro avg       0.76      0.72      0.73      8524\n",
      "weighted avg       0.85      0.86      0.86      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('balanced_classes.hdf5')\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4243   36    3    0    0    0    3]\n",
      " [ 129 1443   59    1    0    0    0]\n",
      " [  23  163  845   55    1    2    0]\n",
      " [  12   10  164  316   34   14    0]\n",
      " [   7    2   18  116   88   55    0]\n",
      " [   5    2    4   25   56  209    0]\n",
      " [  23    2    0    0    0    1  352]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.96      0.99      0.97      4285\n",
      "  2_colonies       0.87      0.88      0.88      1632\n",
      "  3_colonies       0.77      0.78      0.77      1089\n",
      "  4_colonies       0.62      0.57      0.59       550\n",
      "  5_colonies       0.49      0.31      0.38       286\n",
      "  6_colonies       0.74      0.69      0.72       301\n",
      "     outlier       0.99      0.93      0.96       378\n",
      "\n",
      "    accuracy                           0.88      8521\n",
      "   macro avg       0.78      0.74      0.75      8521\n",
      "weighted avg       0.87      0.88      0.88      8521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('balanced_classes.hdf5')\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.9240 - acc: 0.6460 - val_loss: 0.8217 - val_acc: 0.7030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x193ba8cf0b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1, \n",
    "                    steps_per_epoch=1000, \n",
    "                    epochs=1, \n",
    "                    validation_data=validation_generator,\n",
    "                   validation_steps=300,\n",
    "                   class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2740 1107  328   27    0   14   25]\n",
      " [ 221  446  550   94   13  257   15]\n",
      " [ 760   41   21    3    2   45  267]\n",
      " [ 552   15    0    0    0    0    1]\n",
      " [ 277   10    0    0    0    0    1]\n",
      " [ 290   13    0    0    0    0    1]\n",
      " [ 378   10    0    0    0    0    0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.53      0.65      0.58      4241\n",
      "  2_colonies       0.27      0.28      0.28      1596\n",
      "  3_colonies       0.02      0.02      0.02      1139\n",
      "  4_colonies       0.00      0.00      0.00       568\n",
      "  5_colonies       0.00      0.00      0.00       288\n",
      "  6_colonies       0.00      0.00      0.00       304\n",
      "     outlier       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.38      8524\n",
      "   macro avg       0.12      0.13      0.13      8524\n",
      "weighted avg       0.32      0.38      0.34      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19886 images belonging to 7 classes.\n",
      "Found 8521 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(full_training_directory, \n",
    "                                              target_size=(128, 128), \n",
    "                                              color_mode=\"grayscale\", \n",
    "                                              batch_size=batch_size)\n",
    "validation_generator = datagen.flow_from_directory(full_validation_directory,\n",
    "                                                   target_size=(128, 128), \n",
    "                                                   color_mode='grayscale',\n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=False)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "num_test_samples = 8521\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5,5), activation='relu', input_shape=(128,128,1)))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(50, (5,5), activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(100, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(200, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 19:07:58.671031  6536 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0829 19:07:58.739823  6536 deprecation.py:323] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 1.2550 - acc: 0.5578 - val_loss: 0.9274 - val_acc: 0.6666\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.9515 - acc: 0.6396 - val_loss: 0.7597 - val_acc: 0.7155\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.8226 - acc: 0.6859 - val_loss: 0.6752 - val_acc: 0.7455\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.7406 - acc: 0.7178 - val_loss: 0.7279 - val_acc: 0.7370\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.7013 - acc: 0.7309 - val_loss: 0.6729 - val_acc: 0.7380\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.6619 - acc: 0.7485 - val_loss: 0.7039 - val_acc: 0.7371\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.6415 - acc: 0.7545 - val_loss: 0.7163 - val_acc: 0.7201\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.6202 - acc: 0.7666 - val_loss: 0.6544 - val_acc: 0.7440\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5998 - acc: 0.7709 - val_loss: 0.6270 - val_acc: 0.7691\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.5814 - acc: 0.7771 - val_loss: 0.5337 - val_acc: 0.8004\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5671 - acc: 0.7823 - val_loss: 0.4999 - val_acc: 0.8196\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5578 - acc: 0.7866 - val_loss: 0.5061 - val_acc: 0.8049\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5537 - acc: 0.7881 - val_loss: 0.5363 - val_acc: 0.7965\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.5424 - acc: 0.7948 - val_loss: 0.5480 - val_acc: 0.7925\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5339 - acc: 0.7967 - val_loss: 0.5800 - val_acc: 0.7805\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5216 - acc: 0.8034 - val_loss: 0.5805 - val_acc: 0.7810\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.5160 - acc: 0.8041 - val_loss: 0.4855 - val_acc: 0.8197\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5108 - acc: 0.8078 - val_loss: 0.4700 - val_acc: 0.8257\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.5025 - acc: 0.8100 - val_loss: 0.4403 - val_acc: 0.8329\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.5035 - acc: 0.8112 - val_loss: 0.4739 - val_acc: 0.8187\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4914 - acc: 0.8130 - val_loss: 0.4836 - val_acc: 0.8139\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4878 - acc: 0.8158 - val_loss: 0.4912 - val_acc: 0.8151\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4905 - acc: 0.8156 - val_loss: 0.5421 - val_acc: 0.7892\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4772 - acc: 0.8206 - val_loss: 0.5715 - val_acc: 0.7833\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4743 - acc: 0.8222 - val_loss: 0.4320 - val_acc: 0.8412\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4736 - acc: 0.8228 - val_loss: 0.4505 - val_acc: 0.8369\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4651 - acc: 0.8247 - val_loss: 0.4357 - val_acc: 0.8396\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4670 - acc: 0.8235 - val_loss: 0.4206 - val_acc: 0.8433\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4667 - acc: 0.8218 - val_loss: 0.4481 - val_acc: 0.8270\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4539 - acc: 0.8307 - val_loss: 0.4819 - val_acc: 0.8149\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4574 - acc: 0.8257 - val_loss: 0.5143 - val_acc: 0.8066\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4493 - acc: 0.8293 - val_loss: 0.5696 - val_acc: 0.7741\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4522 - acc: 0.8283 - val_loss: 0.4286 - val_acc: 0.8377\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4500 - acc: 0.8305 - val_loss: 0.4231 - val_acc: 0.8439\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4475 - acc: 0.8309 - val_loss: 0.4139 - val_acc: 0.8418\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4432 - acc: 0.8322 - val_loss: 0.4100 - val_acc: 0.8471\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4407 - acc: 0.8336 - val_loss: 0.4416 - val_acc: 0.8304\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4346 - acc: 0.8378 - val_loss: 0.4454 - val_acc: 0.8337\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4342 - acc: 0.8370 - val_loss: 0.4856 - val_acc: 0.8154\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4339 - acc: 0.8375 - val_loss: 0.5459 - val_acc: 0.7841\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4306 - acc: 0.8364 - val_loss: 0.4113 - val_acc: 0.8424\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4267 - acc: 0.8394 - val_loss: 0.3944 - val_acc: 0.8512\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4255 - acc: 0.8371 - val_loss: 0.4431 - val_acc: 0.8395\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4264 - acc: 0.8411 - val_loss: 0.3923 - val_acc: 0.8506\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4208 - acc: 0.8409 - val_loss: 0.4195 - val_acc: 0.8396\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4212 - acc: 0.8412 - val_loss: 0.4748 - val_acc: 0.8268\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4179 - acc: 0.8431 - val_loss: 0.4748 - val_acc: 0.8243\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4218 - acc: 0.8397 - val_loss: 0.5223 - val_acc: 0.7920\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4138 - acc: 0.8436 - val_loss: 0.4201 - val_acc: 0.8451\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.4118 - acc: 0.8432 - val_loss: 0.3803 - val_acc: 0.8581\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4110 - acc: 0.8442 - val_loss: 0.4019 - val_acc: 0.8486\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4138 - acc: 0.8443 - val_loss: 0.3926 - val_acc: 0.8558\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4056 - acc: 0.8457 - val_loss: 0.3985 - val_acc: 0.8528\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4113 - acc: 0.8453 - val_loss: 0.4369 - val_acc: 0.8362\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4018 - acc: 0.8491 - val_loss: 0.4684 - val_acc: 0.8244\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.4019 - acc: 0.8489 - val_loss: 0.5220 - val_acc: 0.7963\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4027 - acc: 0.8474 - val_loss: 0.4716 - val_acc: 0.8264\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3971 - acc: 0.8510 - val_loss: 0.4166 - val_acc: 0.8512\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4023 - acc: 0.8468 - val_loss: 0.4053 - val_acc: 0.8478\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3952 - acc: 0.8482 - val_loss: 0.3932 - val_acc: 0.8525\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4003 - acc: 0.8496 - val_loss: 0.4008 - val_acc: 0.8538\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4007 - acc: 0.8465 - val_loss: 0.4277 - val_acc: 0.8412\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3940 - acc: 0.8505 - val_loss: 0.4472 - val_acc: 0.8324\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3896 - acc: 0.8523 - val_loss: 0.5144 - val_acc: 0.8034\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3930 - acc: 0.8521 - val_loss: 0.4390 - val_acc: 0.8415\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3912 - acc: 0.8513 - val_loss: 0.3739 - val_acc: 0.8588\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3939 - acc: 0.8536 - val_loss: 0.3938 - val_acc: 0.8531\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3906 - acc: 0.8522 - val_loss: 0.3710 - val_acc: 0.8623\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3895 - acc: 0.8536 - val_loss: 0.3909 - val_acc: 0.8535\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3823 - acc: 0.8544 - val_loss: 0.4376 - val_acc: 0.8369\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3836 - acc: 0.8548 - val_loss: 0.4371 - val_acc: 0.8367\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3855 - acc: 0.8540 - val_loss: 0.4917 - val_acc: 0.8124\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3881 - acc: 0.8530 - val_loss: 0.4240 - val_acc: 0.8408\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3815 - acc: 0.8564 - val_loss: 0.3770 - val_acc: 0.8642\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3872 - acc: 0.8512 - val_loss: 0.3753 - val_acc: 0.8637\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3825 - acc: 0.8567 - val_loss: 0.3984 - val_acc: 0.8553\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3793 - acc: 0.8547 - val_loss: 0.3708 - val_acc: 0.8608\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3786 - acc: 0.8558 - val_loss: 0.4166 - val_acc: 0.8438\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3763 - acc: 0.8571 - val_loss: 0.4951 - val_acc: 0.8247\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3750 - acc: 0.8570 - val_loss: 0.4970 - val_acc: 0.8198\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3720 - acc: 0.8586 - val_loss: 0.4428 - val_acc: 0.8354\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3769 - acc: 0.8593 - val_loss: 0.4074 - val_acc: 0.8585\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3771 - acc: 0.8584 - val_loss: 0.3782 - val_acc: 0.8626\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3761 - acc: 0.8562 - val_loss: 0.3861 - val_acc: 0.8635\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3777 - acc: 0.8586 - val_loss: 0.3686 - val_acc: 0.8606\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3705 - acc: 0.8606 - val_loss: 0.4079 - val_acc: 0.8511\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3706 - acc: 0.8579 - val_loss: 0.4455 - val_acc: 0.8416\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3706 - acc: 0.8573 - val_loss: 0.4647 - val_acc: 0.8291\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3718 - acc: 0.8596 - val_loss: 0.4382 - val_acc: 0.8365\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3695 - acc: 0.8600 - val_loss: 0.3777 - val_acc: 0.8575\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3668 - acc: 0.8622 - val_loss: 0.3733 - val_acc: 0.8636\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3618 - acc: 0.8628 - val_loss: 0.3729 - val_acc: 0.8669\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3644 - acc: 0.8616 - val_loss: 0.3733 - val_acc: 0.8623\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3624 - acc: 0.8615 - val_loss: 0.3913 - val_acc: 0.8598\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3669 - acc: 0.8599 - val_loss: 0.4197 - val_acc: 0.8434\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3648 - acc: 0.8611 - val_loss: 0.4951 - val_acc: 0.8116\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3618 - acc: 0.8629 - val_loss: 0.4446 - val_acc: 0.8240\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3645 - acc: 0.8619 - val_loss: 0.3638 - val_acc: 0.8683\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3646 - acc: 0.8611 - val_loss: 0.3684 - val_acc: 0.8620\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3589 - acc: 0.8633 - val_loss: 0.3600 - val_acc: 0.8689\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "balanced_history = model.fit_generator(train_generator,\n",
    "                                       verbose=1, \n",
    "                                       steps_per_epoch=1000, \n",
    "                                       epochs=100 , \n",
    "                                       validation_data=validation_generator,\n",
    "                                      validation_steps=300,\n",
    "                                      class_weight=class_weights)\n",
    "model.save('balanced_gray_classes.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4205   61    9    3    0    1    6]\n",
      " [ 160 1323  140    5    0    2    2]\n",
      " [  25  158  782  115    3    5    1]\n",
      " [  11   12  142  301   46   38    0]\n",
      " [   8    4   16  110   54   94    0]\n",
      " [   5    2    4   26   29  233    2]\n",
      " [  16    4    0    0    0    0  358]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.95      0.98      0.97      4285\n",
      "  2_colonies       0.85      0.81      0.83      1632\n",
      "  3_colonies       0.72      0.72      0.72      1089\n",
      "  4_colonies       0.54      0.55      0.54       550\n",
      "  5_colonies       0.41      0.19      0.26       286\n",
      "  6_colonies       0.62      0.77      0.69       301\n",
      "     outlier       0.97      0.95      0.96       378\n",
      "\n",
      "    accuracy                           0.85      8521\n",
      "   macro avg       0.72      0.71      0.71      8521\n",
      "weighted avg       0.84      0.85      0.85      8521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('balanced_gray_classes.hdf5')\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bff5b65d68>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Segmentation_Data\\\\Labelled_imgs\\\\stratified_data\\\\validation\\\\'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_validation_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
