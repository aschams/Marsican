{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=30, \n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True\n",
    "                            )\n",
    "\n",
    "if 'win32' in sys.platform:\n",
    "    data_directory='F:\\\\Segmentation_Data\\\\'\n",
    "    full_training_directory = data_directory + 'Labelled_imgs\\\\data_for_generator\\\\training\\\\'\n",
    "    full_validation_directory = data_directory +'Labelled_imgs\\\\data_for_generator\\\\validation\\\\'\n",
    "\n",
    "if 'darwin' in sys.platform:\n",
    "    data_directory='/Volumes/Samsung_T5/Segmentation_Data'\n",
    "    full_training_directory = data_directory + 'Labelled_imgs\\\\data_for_generator\\\\training\\\\'\n",
    "    full_validation_directory = data_directory +'Labelled_imgs\\\\data_for_generator\\\\validation\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19890 images belonging to 7 classes.\n",
      "Found 8524 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(full_training_directory, \n",
    "                                              target_size=(128, 128), \n",
    "                                              color_mode=\"rgb\", \n",
    "                                              batch_size=batch_size)\n",
    "validation_generator = datagen.flow_from_directory(full_validation_directory,\n",
    "                                                   target_size=(128, 128), \n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=False)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "num_test_samples = 8524\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0822 18:05:53.412897 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0822 18:05:53.439185 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0822 18:05:53.447649 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0822 18:05:53.471950 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0822 18:05:53.472415 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0822 18:05:55.915113 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0822 18:05:55.956310 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0822 18:05:56.031177 13624 deprecation.py:506] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5,5), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(50, (5,5), activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(100, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(200, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01,\n",
    "                          momentum=0.9,\n",
    "                          decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 1.0679 - acc: 0.6055 - val_loss: 0.7752 - val_acc: 0.7053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x195771bb630>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1, \n",
    "                    steps_per_epoch=1000, \n",
    "                    epochs=1, \n",
    "                    validation_data=validation_generator,\n",
    "                   validation_steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1762 1148  977   18  222   68   46]\n",
      " [ 766   52  162    8  201  121  286]\n",
      " [1101   36    1    0    0    0    1]\n",
      " [ 554   10    3    0    0    0    1]\n",
      " [ 282    4    0    0    0    0    2]\n",
      " [ 300    4    0    0    0    0    0]\n",
      " [ 382    3    2    0    0    0    1]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.34      0.42      0.38      4241\n",
      "  2_colonies       0.04      0.03      0.04      1596\n",
      "  3_colonies       0.00      0.00      0.00      1139\n",
      "  4_colonies       0.00      0.00      0.00       568\n",
      "  5_colonies       0.00      0.00      0.00       288\n",
      "  6_colonies       0.00      0.00      0.00       304\n",
      "     outlier       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.21      8524\n",
      "   macro avg       0.06      0.06      0.06      8524\n",
      "weighted avg       0.18      0.21      0.19      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4148   77    4    1    0    1   10]\n",
      " [ 126 1328  128    6    0    3    5]\n",
      " [  34  174  805  116    5    5    0]\n",
      " [  15   12  125  331   48   37    0]\n",
      " [   5    2   11   98   67  105    0]\n",
      " [   7    1    5   22   23  212   34]\n",
      " [  40    7    1    0    0    0  340]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.95      0.98      0.96      4241\n",
      "  2_colonies       0.83      0.83      0.83      1596\n",
      "  3_colonies       0.75      0.71      0.73      1139\n",
      "  4_colonies       0.58      0.58      0.58       568\n",
      "  5_colonies       0.47      0.23      0.31       288\n",
      "  6_colonies       0.58      0.70      0.64       304\n",
      "     outlier       0.87      0.88      0.88       388\n",
      "\n",
      "    accuracy                           0.85      8524\n",
      "   macro avg       0.72      0.70      0.70      8524\n",
      "weighted avg       0.84      0.85      0.84      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 18:06:15.504884 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0822 18:06:15.572340 13624 deprecation.py:323] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 1.2578 - acc: 0.5642 - val_loss: 0.9296 - val_acc: 0.6526\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.9432 - acc: 0.6464 - val_loss: 0.7786 - val_acc: 0.7135\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.8306 - acc: 0.6833 - val_loss: 0.7435 - val_acc: 0.7183\n",
      "Epoch 4/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.7664 - acc: 0.7074 - val_loss: 0.6653 - val_acc: 0.7457\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.7080 - acc: 0.7277 - val_loss: 0.7551 - val_acc: 0.7076\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6670 - acc: 0.7421 - val_loss: 0.6814 - val_acc: 0.7409\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6365 - acc: 0.7516 - val_loss: 0.6727 - val_acc: 0.7340\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6127 - acc: 0.7684 - val_loss: 0.6558 - val_acc: 0.7494\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.5869 - acc: 0.7767 - val_loss: 0.5511 - val_acc: 0.7965\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5694 - acc: 0.7830 - val_loss: 0.5024 - val_acc: 0.8101\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5670 - acc: 0.7850 - val_loss: 0.4888 - val_acc: 0.8142\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5426 - acc: 0.7919 - val_loss: 0.4921 - val_acc: 0.8151\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5389 - acc: 0.7926 - val_loss: 0.5276 - val_acc: 0.8032\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.5234 - acc: 0.7994 - val_loss: 0.5711 - val_acc: 0.7770\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5142 - acc: 0.8038 - val_loss: 0.6139 - val_acc: 0.7674\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.5089 - acc: 0.8076 - val_loss: 0.6005 - val_acc: 0.7762\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.5060 - acc: 0.8075 - val_loss: 0.4882 - val_acc: 0.8159\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4955 - acc: 0.8142 - val_loss: 0.4499 - val_acc: 0.8359\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4909 - acc: 0.8129 - val_loss: 0.4423 - val_acc: 0.8323\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4878 - acc: 0.8153 - val_loss: 0.4365 - val_acc: 0.8408\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4818 - acc: 0.8169 - val_loss: 0.5037 - val_acc: 0.8147\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4720 - acc: 0.8187 - val_loss: 0.5092 - val_acc: 0.8063\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4729 - acc: 0.8208 - val_loss: 0.5462 - val_acc: 0.7927\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4657 - acc: 0.8218 - val_loss: 0.5826 - val_acc: 0.7795\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4577 - acc: 0.8266 - val_loss: 0.4413 - val_acc: 0.8363\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4626 - acc: 0.8239 - val_loss: 0.4317 - val_acc: 0.8387\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4604 - acc: 0.8249 - val_loss: 0.4202 - val_acc: 0.8362\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4506 - acc: 0.8270 - val_loss: 0.4130 - val_acc: 0.8452\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4462 - acc: 0.8315 - val_loss: 0.4868 - val_acc: 0.8199\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4460 - acc: 0.8303 - val_loss: 0.4641 - val_acc: 0.8262\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4384 - acc: 0.8310 - val_loss: 0.5118 - val_acc: 0.8096\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4407 - acc: 0.8310 - val_loss: 0.5486 - val_acc: 0.7929\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4389 - acc: 0.8336 - val_loss: 0.4251 - val_acc: 0.8435\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4370 - acc: 0.8346 - val_loss: 0.4151 - val_acc: 0.8486\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4293 - acc: 0.8353 - val_loss: 0.4117 - val_acc: 0.8449\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4279 - acc: 0.8352 - val_loss: 0.4015 - val_acc: 0.8515\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4267 - acc: 0.8378 - val_loss: 0.4353 - val_acc: 0.8398\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4259 - acc: 0.8375 - val_loss: 0.4552 - val_acc: 0.8354\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4250 - acc: 0.8368 - val_loss: 0.5018 - val_acc: 0.8110\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4199 - acc: 0.8412 - val_loss: 0.5436 - val_acc: 0.7898\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4191 - acc: 0.8412 - val_loss: 0.4131 - val_acc: 0.8481\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4164 - acc: 0.8419 - val_loss: 0.4054 - val_acc: 0.8547\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4126 - acc: 0.8418 - val_loss: 0.4168 - val_acc: 0.8505\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4147 - acc: 0.8423 - val_loss: 0.3984 - val_acc: 0.8532\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4094 - acc: 0.8443 - val_loss: 0.4253 - val_acc: 0.8384\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4053 - acc: 0.8462 - val_loss: 0.4370 - val_acc: 0.8416\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4057 - acc: 0.8455 - val_loss: 0.4764 - val_acc: 0.8275\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4004 - acc: 0.8497 - val_loss: 0.5337 - val_acc: 0.8006\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4025 - acc: 0.8482 - val_loss: 0.4254 - val_acc: 0.8464\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4074 - acc: 0.8465 - val_loss: 0.3912 - val_acc: 0.8592\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4012 - acc: 0.8484 - val_loss: 0.3894 - val_acc: 0.8598\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4043 - acc: 0.8475 - val_loss: 0.3776 - val_acc: 0.8614\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3953 - acc: 0.8514 - val_loss: 0.4156 - val_acc: 0.8593\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3944 - acc: 0.8504 - val_loss: 0.4501 - val_acc: 0.8359\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3931 - acc: 0.8506 - val_loss: 0.4760 - val_acc: 0.8272\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3934 - acc: 0.8498 - val_loss: 0.5346 - val_acc: 0.7963\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3907 - acc: 0.8523 - val_loss: 0.4249 - val_acc: 0.8462\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3877 - acc: 0.8521 - val_loss: 0.3922 - val_acc: 0.8581\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3901 - acc: 0.8510 - val_loss: 0.3888 - val_acc: 0.8561\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3817 - acc: 0.8543 - val_loss: 0.3858 - val_acc: 0.8590\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3895 - acc: 0.8532 - val_loss: 0.4134 - val_acc: 0.8449\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3823 - acc: 0.8551 - val_loss: 0.4322 - val_acc: 0.8423\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3870 - acc: 0.8544 - val_loss: 0.4589 - val_acc: 0.8328\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3833 - acc: 0.8559 - val_loss: 0.4986 - val_acc: 0.8151\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3768 - acc: 0.8561 - val_loss: 0.4394 - val_acc: 0.8448\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3830 - acc: 0.8566 - val_loss: 0.3738 - val_acc: 0.8585\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3773 - acc: 0.8555 - val_loss: 0.3816 - val_acc: 0.8591\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3801 - acc: 0.8553 - val_loss: 0.3921 - val_acc: 0.8597\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3751 - acc: 0.8576 - val_loss: 0.3891 - val_acc: 0.8621\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3717 - acc: 0.8572 - val_loss: 0.4311 - val_acc: 0.8439\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3716 - acc: 0.8571 - val_loss: 0.4558 - val_acc: 0.8309\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 123s 123ms/step - loss: 0.3683 - acc: 0.8606 - val_loss: 0.5052 - val_acc: 0.80911s - loss: 0.3682 - \n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3758 - acc: 0.8566 - val_loss: 0.4438 - val_acc: 0.8361\n",
      "Epoch 74/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3701 - acc: 0.8586 - val_loss: 0.3622 - val_acc: 0.8641\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3711 - acc: 0.8594 - val_loss: 0.3739 - val_acc: 0.8609\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 0.3705 - acc: 0.8612 - val_loss: 0.3830 - val_acc: 0.8619\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3667 - acc: 0.8604 - val_loss: 0.3791 - val_acc: 0.8640\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3642 - acc: 0.8629 - val_loss: 0.4151 - val_acc: 0.8526\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3678 - acc: 0.8597 - val_loss: 0.4520 - val_acc: 0.8342\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 124s 124ms/step - loss: 0.3683 - acc: 0.8613 - val_loss: 0.4723 - val_acc: 0.8236\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3653 - acc: 0.8603 - val_loss: 0.4444 - val_acc: 0.8329\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3614 - acc: 0.8604 - val_loss: 0.3844 - val_acc: 0.8674\n",
      "Epoch 83/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3595 - acc: 0.8646 - val_loss: 0.3744 - val_acc: 0.8641\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3639 - acc: 0.8599 - val_loss: 0.3706 - val_acc: 0.8654\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3581 - acc: 0.8647 - val_loss: 0.3705 - val_acc: 0.8672\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3658 - acc: 0.8615 - val_loss: 0.4106 - val_acc: 0.8518\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3607 - acc: 0.8618 - val_loss: 0.4355 - val_acc: 0.8377\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3569 - acc: 0.8626 - val_loss: 0.4698 - val_acc: 0.8265\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3595 - acc: 0.8641 - val_loss: 0.4490 - val_acc: 0.8302\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3560 - acc: 0.8651 - val_loss: 0.3656 - val_acc: 0.8651\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3565 - acc: 0.8631 - val_loss: 0.3743 - val_acc: 0.8690\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3578 - acc: 0.8623 - val_loss: 0.3604 - val_acc: 0.8672\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3539 - acc: 0.8661 - val_loss: 0.3694 - val_acc: 0.8666\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3555 - acc: 0.8659 - val_loss: 0.4090 - val_acc: 0.8535\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3511 - acc: 0.8666 - val_loss: 0.4275 - val_acc: 0.8441\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3555 - acc: 0.8629 - val_loss: 0.4652 - val_acc: 0.8325\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3543 - acc: 0.8640 - val_loss: 0.4573 - val_acc: 0.8288\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3481 - acc: 0.8660 - val_loss: 0.3657 - val_acc: 0.8658\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3520 - acc: 0.8640 - val_loss: 0.3659 - val_acc: 0.8651\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3551 - acc: 0.8641 - val_loss: 0.3592 - val_acc: 0.8678\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3521 - acc: 0.8653 - val_loss: 0.3713 - val_acc: 0.8621\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3467 - acc: 0.8673 - val_loss: 0.3991 - val_acc: 0.8553\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3474 - acc: 0.8664 - val_loss: 0.4398 - val_acc: 0.8430\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3502 - acc: 0.8652 - val_loss: 0.4633 - val_acc: 0.8277\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3445 - acc: 0.8668 - val_loss: 0.4551 - val_acc: 0.8312\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3472 - acc: 0.8655 - val_loss: 0.3818 - val_acc: 0.8685\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3452 - acc: 0.8660 - val_loss: 0.3723 - val_acc: 0.8661\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3516 - acc: 0.8669 - val_loss: 0.3644 - val_acc: 0.8701\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3433 - acc: 0.8669 - val_loss: 0.3760 - val_acc: 0.8593\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3456 - acc: 0.8663 - val_loss: 0.3980 - val_acc: 0.8599\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3460 - acc: 0.8691 - val_loss: 0.4059 - val_acc: 0.8522\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3364 - acc: 0.8716 - val_loss: 0.4504 - val_acc: 0.8350\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3397 - acc: 0.8683 - val_loss: 0.4674 - val_acc: 0.8213\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3415 - acc: 0.8698 - val_loss: 0.3713 - val_acc: 0.8628\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3431 - acc: 0.8664 - val_loss: 0.3676 - val_acc: 0.8660\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3449 - acc: 0.8701 - val_loss: 0.3567 - val_acc: 0.8734\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3438 - acc: 0.8679 - val_loss: 0.3621 - val_acc: 0.8697\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3382 - acc: 0.8705 - val_loss: 0.3776 - val_acc: 0.8612\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3386 - acc: 0.8691 - val_loss: 0.4373 - val_acc: 0.8474\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3360 - acc: 0.8694 - val_loss: 0.4420 - val_acc: 0.8357\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3374 - acc: 0.8713 - val_loss: 0.4796 - val_acc: 0.8228\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3315 - acc: 0.8721 - val_loss: 0.3720 - val_acc: 0.8698\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3390 - acc: 0.8709 - val_loss: 0.3509 - val_acc: 0.8738\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3369 - acc: 0.8719 - val_loss: 0.3568 - val_acc: 0.87410.3375 - - ETA: 0s - loss: 0.3368 - acc: 0.87\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3377 - acc: 0.8713 - val_loss: 0.3557 - val_acc: 0.8697\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3319 - acc: 0.8724 - val_loss: 0.3840 - val_acc: 0.8598\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3372 - acc: 0.8703 - val_loss: 0.4057 - val_acc: 0.8538\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3315 - acc: 0.8726 - val_loss: 0.4306 - val_acc: 0.8414\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3350 - acc: 0.8730 - val_loss: 0.4781 - val_acc: 0.8188\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3294 - acc: 0.8746 - val_loss: 0.3684 - val_acc: 0.8640\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3300 - acc: 0.8740 - val_loss: 0.3661 - val_acc: 0.8721\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3282 - acc: 0.8747 - val_loss: 0.3732 - val_acc: 0.8668\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3294 - acc: 0.8719 - val_loss: 0.3588 - val_acc: 0.8738\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3343 - acc: 0.8729 - val_loss: 0.3732 - val_acc: 0.8658\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3324 - acc: 0.8716 - val_loss: 0.4084 - val_acc: 0.8546\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3296 - acc: 0.8716 - val_loss: 0.4429 - val_acc: 0.8395\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3258 - acc: 0.8740 - val_loss: 0.4779 - val_acc: 0.8218\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3310 - acc: 0.8734 - val_loss: 0.3784 - val_acc: 0.8650\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3274 - acc: 0.8729 - val_loss: 0.3544 - val_acc: 0.8717\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3293 - acc: 0.8747 - val_loss: 0.3632 - val_acc: 0.8738\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3237 - acc: 0.8774 - val_loss: 0.3607 - val_acc: 0.8698\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3302 - acc: 0.8717 - val_loss: 0.3639 - val_acc: 0.8695\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3302 - acc: 0.8719 - val_loss: 0.4058 - val_acc: 0.8501\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3187 - acc: 0.8768 - val_loss: 0.4418 - val_acc: 0.8397\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3250 - acc: 0.8758 - val_loss: 0.4821 - val_acc: 0.8167\n",
      "Epoch 146/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3257 - acc: 0.8726 - val_loss: 0.3917 - val_acc: 0.8606\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3225 - acc: 0.8770 - val_loss: 0.3603 - val_acc: 0.8723\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3246 - acc: 0.8754 - val_loss: 0.3664 - val_acc: 0.8697\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3230 - acc: 0.8753 - val_loss: 0.3736 - val_acc: 0.8620- loss: 0.3220 - ac - ETA: 2s - loss: 0.3223 - acc: 0.875 - ETA: 1s - loss:\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3216 - acc: 0.8765 - val_loss: 0.3747 - val_acc: 0.8687\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "balanced_history = model.fit_generator(train_generator,\n",
    "                                       verbose=1, \n",
    "                                       steps_per_epoch=1000, \n",
    "                                       epochs=150 , \n",
    "                                       validation_data=validation_generator,\n",
    "                                      validation_steps=300,\n",
    "                                      class_weight=class_weights)\n",
    "model.save('balanced_classes.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4187   46    2    0    0    0    6]\n",
      " [ 141 1348   99    5    0    2    1]\n",
      " [  40  194  840   59    4    1    1]\n",
      " [  14   15  165  322   36   16    0]\n",
      " [   5    2   24  114   82   61    0]\n",
      " [   9    1    4   32   47  210    1]\n",
      " [  25    9    1    0    0    0  353]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.95      0.99      0.97      4241\n",
      "  2_colonies       0.83      0.84      0.84      1596\n",
      "  3_colonies       0.74      0.74      0.74      1139\n",
      "  4_colonies       0.61      0.57      0.59       568\n",
      "  5_colonies       0.49      0.28      0.36       288\n",
      "  6_colonies       0.72      0.69      0.71       304\n",
      "     outlier       0.98      0.91      0.94       388\n",
      "\n",
      "    accuracy                           0.86      8524\n",
      "   macro avg       0.76      0.72      0.73      8524\n",
      "weighted avg       0.85      0.86      0.86      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('balanced_classes.hdf5')\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.9240 - acc: 0.6460 - val_loss: 0.8217 - val_acc: 0.7030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x193ba8cf0b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1, \n",
    "                    steps_per_epoch=1000, \n",
    "                    epochs=1, \n",
    "                    validation_data=validation_generator,\n",
    "                   validation_steps=300,\n",
    "                   class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2740 1107  328   27    0   14   25]\n",
      " [ 221  446  550   94   13  257   15]\n",
      " [ 760   41   21    3    2   45  267]\n",
      " [ 552   15    0    0    0    0    1]\n",
      " [ 277   10    0    0    0    0    1]\n",
      " [ 290   13    0    0    0    0    1]\n",
      " [ 378   10    0    0    0    0    0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.53      0.65      0.58      4241\n",
      "  2_colonies       0.27      0.28      0.28      1596\n",
      "  3_colonies       0.02      0.02      0.02      1139\n",
      "  4_colonies       0.00      0.00      0.00       568\n",
      "  5_colonies       0.00      0.00      0.00       288\n",
      "  6_colonies       0.00      0.00      0.00       304\n",
      "     outlier       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.38      8524\n",
      "   macro avg       0.12      0.13      0.13      8524\n",
      "weighted avg       0.32      0.38      0.34      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
