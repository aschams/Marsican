{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "sys.path.append( '../../src')\n",
    "import counting_functions as mcf\n",
    "import marsican_functions as msn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=30, \n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True)\n",
    "\n",
    "if 'win32' in sys.platform:\n",
    "    data_directory='F:\\\\Segmentation_Data\\\\'\n",
    "    full_training_directory = data_directory + 'Labelled_imgs\\\\stratified_data\\\\training\\\\'\n",
    "    full_validation_directory = data_directory +'Labelled_imgs\\\\stratified_data\\\\validation\\\\'\n",
    "\n",
    "if 'darwin' in sys.platform:\n",
    "    data_directory='/Volumes/Samsung_T5/Segmentation_Data/'\n",
    "    full_training_directory = data_directory + 'Labelled_imgs/stratified_data/training/'\n",
    "    full_validation_directory = data_directory +'Labelled_imgs/stratified_data/validation/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21555 images belonging to 8 classes.\n",
      "Found 9236 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(full_training_directory, \n",
    "                                              target_size=(128, 128), \n",
    "                                              color_mode=\"rgb\", \n",
    "                                              batch_size=batch_size)\n",
    "validation_generator = datagen.flow_from_directory(full_validation_directory,\n",
    "                                                   target_size=(128, 128), \n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=False)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "num_test_samples = 8984\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 23:00:44.752855  8920 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0830 23:00:44.778785  8920 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0830 23:00:44.786794  8920 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0830 23:00:44.810701  8920 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0830 23:00:44.811698  8920 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0830 23:00:47.161642  8920 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0830 23:00:47.204526  8920 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0830 23:00:47.280323  8920 deprecation.py:506] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5,5), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(50, (5,5), activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(100, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(200, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01,\n",
    "                          momentum=0.9,\n",
    "                          decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 1.0679 - acc: 0.6055 - val_loss: 0.7752 - val_acc: 0.7053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x195771bb630>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1, \n",
    "                    steps_per_epoch=1000, \n",
    "                    epochs=1, \n",
    "                    validation_data=validation_generator,\n",
    "                   validation_steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1762 1148  977   18  222   68   46]\n",
      " [ 766   52  162    8  201  121  286]\n",
      " [1101   36    1    0    0    0    1]\n",
      " [ 554   10    3    0    0    0    1]\n",
      " [ 282    4    0    0    0    0    2]\n",
      " [ 300    4    0    0    0    0    0]\n",
      " [ 382    3    2    0    0    0    1]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.34      0.42      0.38      4241\n",
      "  2_colonies       0.04      0.03      0.04      1596\n",
      "  3_colonies       0.00      0.00      0.00      1139\n",
      "  4_colonies       0.00      0.00      0.00       568\n",
      "  5_colonies       0.00      0.00      0.00       288\n",
      "  6_colonies       0.00      0.00      0.00       304\n",
      "     outlier       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.21      8524\n",
      "   macro avg       0.06      0.06      0.06      8524\n",
      "weighted avg       0.18      0.21      0.19      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0_colonies','1_colony', \n",
    "                '2_colonies', '3_colonies',\n",
    "                '4_colonies', '5_colonies', \n",
    "                '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4148   77    4    1    0    1   10]\n",
      " [ 126 1328  128    6    0    3    5]\n",
      " [  34  174  805  116    5    5    0]\n",
      " [  15   12  125  331   48   37    0]\n",
      " [   5    2   11   98   67  105    0]\n",
      " [   7    1    5   22   23  212   34]\n",
      " [  40    7    1    0    0    0  340]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.95      0.98      0.96      4241\n",
      "  2_colonies       0.83      0.83      0.83      1596\n",
      "  3_colonies       0.75      0.71      0.73      1139\n",
      "  4_colonies       0.58      0.58      0.58       568\n",
      "  5_colonies       0.47      0.23      0.31       288\n",
      "  6_colonies       0.58      0.70      0.64       304\n",
      "     outlier       0.87      0.88      0.88       388\n",
      "\n",
      "    accuracy                           0.85      8524\n",
      "   macro avg       0.72      0.70      0.70      8524\n",
      "weighted avg       0.84      0.85      0.84      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/RyanAkilos/3808c17f79e77c4117de35aa68447045\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 18:06:15.504884 13624 deprecation_wrapper.py:119] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0822 18:06:15.572340 13624 deprecation.py:323] From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 1.2578 - acc: 0.5642 - val_loss: 0.9296 - val_acc: 0.6526\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.9432 - acc: 0.6464 - val_loss: 0.7786 - val_acc: 0.7135\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.8306 - acc: 0.6833 - val_loss: 0.7435 - val_acc: 0.7183\n",
      "Epoch 4/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.7664 - acc: 0.7074 - val_loss: 0.6653 - val_acc: 0.7457\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.7080 - acc: 0.7277 - val_loss: 0.7551 - val_acc: 0.7076\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6670 - acc: 0.7421 - val_loss: 0.6814 - val_acc: 0.7409\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6365 - acc: 0.7516 - val_loss: 0.6727 - val_acc: 0.7340\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.6127 - acc: 0.7684 - val_loss: 0.6558 - val_acc: 0.7494\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.5869 - acc: 0.7767 - val_loss: 0.5511 - val_acc: 0.7965\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5694 - acc: 0.7830 - val_loss: 0.5024 - val_acc: 0.8101\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5670 - acc: 0.7850 - val_loss: 0.4888 - val_acc: 0.8142\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5426 - acc: 0.7919 - val_loss: 0.4921 - val_acc: 0.8151\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5389 - acc: 0.7926 - val_loss: 0.5276 - val_acc: 0.8032\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.5234 - acc: 0.7994 - val_loss: 0.5711 - val_acc: 0.7770\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.5142 - acc: 0.8038 - val_loss: 0.6139 - val_acc: 0.7674\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.5089 - acc: 0.8076 - val_loss: 0.6005 - val_acc: 0.7762\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.5060 - acc: 0.8075 - val_loss: 0.4882 - val_acc: 0.8159\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4955 - acc: 0.8142 - val_loss: 0.4499 - val_acc: 0.8359\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4909 - acc: 0.8129 - val_loss: 0.4423 - val_acc: 0.8323\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4878 - acc: 0.8153 - val_loss: 0.4365 - val_acc: 0.8408\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4818 - acc: 0.8169 - val_loss: 0.5037 - val_acc: 0.8147\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4720 - acc: 0.8187 - val_loss: 0.5092 - val_acc: 0.8063\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4729 - acc: 0.8208 - val_loss: 0.5462 - val_acc: 0.7927\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4657 - acc: 0.8218 - val_loss: 0.5826 - val_acc: 0.7795\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4577 - acc: 0.8266 - val_loss: 0.4413 - val_acc: 0.8363\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4626 - acc: 0.8239 - val_loss: 0.4317 - val_acc: 0.8387\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4604 - acc: 0.8249 - val_loss: 0.4202 - val_acc: 0.8362\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4506 - acc: 0.8270 - val_loss: 0.4130 - val_acc: 0.8452\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4462 - acc: 0.8315 - val_loss: 0.4868 - val_acc: 0.8199\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4460 - acc: 0.8303 - val_loss: 0.4641 - val_acc: 0.8262\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4384 - acc: 0.8310 - val_loss: 0.5118 - val_acc: 0.8096\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4407 - acc: 0.8310 - val_loss: 0.5486 - val_acc: 0.7929\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4389 - acc: 0.8336 - val_loss: 0.4251 - val_acc: 0.8435\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4370 - acc: 0.8346 - val_loss: 0.4151 - val_acc: 0.8486\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.4293 - acc: 0.8353 - val_loss: 0.4117 - val_acc: 0.8449\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4279 - acc: 0.8352 - val_loss: 0.4015 - val_acc: 0.8515\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4267 - acc: 0.8378 - val_loss: 0.4353 - val_acc: 0.8398\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4259 - acc: 0.8375 - val_loss: 0.4552 - val_acc: 0.8354\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4250 - acc: 0.8368 - val_loss: 0.5018 - val_acc: 0.8110\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4199 - acc: 0.8412 - val_loss: 0.5436 - val_acc: 0.7898\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4191 - acc: 0.8412 - val_loss: 0.4131 - val_acc: 0.8481\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4164 - acc: 0.8419 - val_loss: 0.4054 - val_acc: 0.8547\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4126 - acc: 0.8418 - val_loss: 0.4168 - val_acc: 0.8505\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4147 - acc: 0.8423 - val_loss: 0.3984 - val_acc: 0.8532\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4094 - acc: 0.8443 - val_loss: 0.4253 - val_acc: 0.8384\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4053 - acc: 0.8462 - val_loss: 0.4370 - val_acc: 0.8416\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4057 - acc: 0.8455 - val_loss: 0.4764 - val_acc: 0.8275\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4004 - acc: 0.8497 - val_loss: 0.5337 - val_acc: 0.8006\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.4025 - acc: 0.8482 - val_loss: 0.4254 - val_acc: 0.8464\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4074 - acc: 0.8465 - val_loss: 0.3912 - val_acc: 0.8592\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4012 - acc: 0.8484 - val_loss: 0.3894 - val_acc: 0.8598\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.4043 - acc: 0.8475 - val_loss: 0.3776 - val_acc: 0.8614\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3953 - acc: 0.8514 - val_loss: 0.4156 - val_acc: 0.8593\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3944 - acc: 0.8504 - val_loss: 0.4501 - val_acc: 0.8359\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3931 - acc: 0.8506 - val_loss: 0.4760 - val_acc: 0.8272\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3934 - acc: 0.8498 - val_loss: 0.5346 - val_acc: 0.7963\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3907 - acc: 0.8523 - val_loss: 0.4249 - val_acc: 0.8462\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3877 - acc: 0.8521 - val_loss: 0.3922 - val_acc: 0.8581\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3901 - acc: 0.8510 - val_loss: 0.3888 - val_acc: 0.8561\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3817 - acc: 0.8543 - val_loss: 0.3858 - val_acc: 0.8590\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3895 - acc: 0.8532 - val_loss: 0.4134 - val_acc: 0.8449\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3823 - acc: 0.8551 - val_loss: 0.4322 - val_acc: 0.8423\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3870 - acc: 0.8544 - val_loss: 0.4589 - val_acc: 0.8328\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3833 - acc: 0.8559 - val_loss: 0.4986 - val_acc: 0.8151\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3768 - acc: 0.8561 - val_loss: 0.4394 - val_acc: 0.8448\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3830 - acc: 0.8566 - val_loss: 0.3738 - val_acc: 0.8585\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3773 - acc: 0.8555 - val_loss: 0.3816 - val_acc: 0.8591\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3801 - acc: 0.8553 - val_loss: 0.3921 - val_acc: 0.8597\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3751 - acc: 0.8576 - val_loss: 0.3891 - val_acc: 0.8621\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3717 - acc: 0.8572 - val_loss: 0.4311 - val_acc: 0.8439\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3716 - acc: 0.8571 - val_loss: 0.4558 - val_acc: 0.8309\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 123s 123ms/step - loss: 0.3683 - acc: 0.8606 - val_loss: 0.5052 - val_acc: 0.80911s - loss: 0.3682 - \n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3758 - acc: 0.8566 - val_loss: 0.4438 - val_acc: 0.8361\n",
      "Epoch 74/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3701 - acc: 0.8586 - val_loss: 0.3622 - val_acc: 0.8641\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3711 - acc: 0.8594 - val_loss: 0.3739 - val_acc: 0.8609\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 0.3705 - acc: 0.8612 - val_loss: 0.3830 - val_acc: 0.8619\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3667 - acc: 0.8604 - val_loss: 0.3791 - val_acc: 0.8640\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3642 - acc: 0.8629 - val_loss: 0.4151 - val_acc: 0.8526\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3678 - acc: 0.8597 - val_loss: 0.4520 - val_acc: 0.8342\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 124s 124ms/step - loss: 0.3683 - acc: 0.8613 - val_loss: 0.4723 - val_acc: 0.8236\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3653 - acc: 0.8603 - val_loss: 0.4444 - val_acc: 0.8329\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3614 - acc: 0.8604 - val_loss: 0.3844 - val_acc: 0.8674\n",
      "Epoch 83/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3595 - acc: 0.8646 - val_loss: 0.3744 - val_acc: 0.8641\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3639 - acc: 0.8599 - val_loss: 0.3706 - val_acc: 0.8654\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3581 - acc: 0.8647 - val_loss: 0.3705 - val_acc: 0.8672\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3658 - acc: 0.8615 - val_loss: 0.4106 - val_acc: 0.8518\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3607 - acc: 0.8618 - val_loss: 0.4355 - val_acc: 0.8377\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3569 - acc: 0.8626 - val_loss: 0.4698 - val_acc: 0.8265\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3595 - acc: 0.8641 - val_loss: 0.4490 - val_acc: 0.8302\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3560 - acc: 0.8651 - val_loss: 0.3656 - val_acc: 0.8651\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3565 - acc: 0.8631 - val_loss: 0.3743 - val_acc: 0.8690\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3578 - acc: 0.8623 - val_loss: 0.3604 - val_acc: 0.8672\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3539 - acc: 0.8661 - val_loss: 0.3694 - val_acc: 0.8666\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3555 - acc: 0.8659 - val_loss: 0.4090 - val_acc: 0.8535\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3511 - acc: 0.8666 - val_loss: 0.4275 - val_acc: 0.8441\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3555 - acc: 0.8629 - val_loss: 0.4652 - val_acc: 0.8325\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3543 - acc: 0.8640 - val_loss: 0.4573 - val_acc: 0.8288\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3481 - acc: 0.8660 - val_loss: 0.3657 - val_acc: 0.8658\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3520 - acc: 0.8640 - val_loss: 0.3659 - val_acc: 0.8651\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3551 - acc: 0.8641 - val_loss: 0.3592 - val_acc: 0.8678\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3521 - acc: 0.8653 - val_loss: 0.3713 - val_acc: 0.8621\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3467 - acc: 0.8673 - val_loss: 0.3991 - val_acc: 0.8553\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 121s 121ms/step - loss: 0.3474 - acc: 0.8664 - val_loss: 0.4398 - val_acc: 0.8430\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3502 - acc: 0.8652 - val_loss: 0.4633 - val_acc: 0.8277\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3445 - acc: 0.8668 - val_loss: 0.4551 - val_acc: 0.8312\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3472 - acc: 0.8655 - val_loss: 0.3818 - val_acc: 0.8685\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3452 - acc: 0.8660 - val_loss: 0.3723 - val_acc: 0.8661\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3516 - acc: 0.8669 - val_loss: 0.3644 - val_acc: 0.8701\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3433 - acc: 0.8669 - val_loss: 0.3760 - val_acc: 0.8593\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3456 - acc: 0.8663 - val_loss: 0.3980 - val_acc: 0.8599\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3460 - acc: 0.8691 - val_loss: 0.4059 - val_acc: 0.8522\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3364 - acc: 0.8716 - val_loss: 0.4504 - val_acc: 0.8350\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3397 - acc: 0.8683 - val_loss: 0.4674 - val_acc: 0.8213\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3415 - acc: 0.8698 - val_loss: 0.3713 - val_acc: 0.8628\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3431 - acc: 0.8664 - val_loss: 0.3676 - val_acc: 0.8660\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3449 - acc: 0.8701 - val_loss: 0.3567 - val_acc: 0.8734\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3438 - acc: 0.8679 - val_loss: 0.3621 - val_acc: 0.8697\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3382 - acc: 0.8705 - val_loss: 0.3776 - val_acc: 0.8612\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3386 - acc: 0.8691 - val_loss: 0.4373 - val_acc: 0.8474\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3360 - acc: 0.8694 - val_loss: 0.4420 - val_acc: 0.8357\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3374 - acc: 0.8713 - val_loss: 0.4796 - val_acc: 0.8228\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3315 - acc: 0.8721 - val_loss: 0.3720 - val_acc: 0.8698\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3390 - acc: 0.8709 - val_loss: 0.3509 - val_acc: 0.8738\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3369 - acc: 0.8719 - val_loss: 0.3568 - val_acc: 0.87410.3375 - - ETA: 0s - loss: 0.3368 - acc: 0.87\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3377 - acc: 0.8713 - val_loss: 0.3557 - val_acc: 0.8697\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3319 - acc: 0.8724 - val_loss: 0.3840 - val_acc: 0.8598\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3372 - acc: 0.8703 - val_loss: 0.4057 - val_acc: 0.8538\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3315 - acc: 0.8726 - val_loss: 0.4306 - val_acc: 0.8414\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3350 - acc: 0.8730 - val_loss: 0.4781 - val_acc: 0.8188\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3294 - acc: 0.8746 - val_loss: 0.3684 - val_acc: 0.8640\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3300 - acc: 0.8740 - val_loss: 0.3661 - val_acc: 0.8721\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3282 - acc: 0.8747 - val_loss: 0.3732 - val_acc: 0.8668\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3294 - acc: 0.8719 - val_loss: 0.3588 - val_acc: 0.8738\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3343 - acc: 0.8729 - val_loss: 0.3732 - val_acc: 0.8658\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3324 - acc: 0.8716 - val_loss: 0.4084 - val_acc: 0.8546\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3296 - acc: 0.8716 - val_loss: 0.4429 - val_acc: 0.8395\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3258 - acc: 0.8740 - val_loss: 0.4779 - val_acc: 0.8218\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3310 - acc: 0.8734 - val_loss: 0.3784 - val_acc: 0.8650\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3274 - acc: 0.8729 - val_loss: 0.3544 - val_acc: 0.8717\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3293 - acc: 0.8747 - val_loss: 0.3632 - val_acc: 0.8738\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3237 - acc: 0.8774 - val_loss: 0.3607 - val_acc: 0.8698\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3302 - acc: 0.8717 - val_loss: 0.3639 - val_acc: 0.8695\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3302 - acc: 0.8719 - val_loss: 0.4058 - val_acc: 0.8501\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3187 - acc: 0.8768 - val_loss: 0.4418 - val_acc: 0.8397\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.3250 - acc: 0.8758 - val_loss: 0.4821 - val_acc: 0.8167\n",
      "Epoch 146/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3257 - acc: 0.8726 - val_loss: 0.3917 - val_acc: 0.8606\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3225 - acc: 0.8770 - val_loss: 0.3603 - val_acc: 0.8723\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3246 - acc: 0.8754 - val_loss: 0.3664 - val_acc: 0.8697\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3230 - acc: 0.8753 - val_loss: 0.3736 - val_acc: 0.8620- loss: 0.3220 - ac - ETA: 2s - loss: 0.3223 - acc: 0.875 - ETA: 1s - loss:\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.3216 - acc: 0.8765 - val_loss: 0.3747 - val_acc: 0.8687\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "balanced_history = model.fit_generator(train_generator,\n",
    "                                       verbose=1, \n",
    "                                       steps_per_epoch=1000, \n",
    "                                       epochs=100 , \n",
    "                                       validation_data=validation_generator,\n",
    "                                      validation_steps=300,\n",
    "                                      class_weight=class_weights)\n",
    "model.save('balanced_classes.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4187   46    2    0    0    0    6]\n",
      " [ 141 1348   99    5    0    2    1]\n",
      " [  40  194  840   59    4    1    1]\n",
      " [  14   15  165  322   36   16    0]\n",
      " [   5    2   24  114   82   61    0]\n",
      " [   9    1    4   32   47  210    1]\n",
      " [  25    9    1    0    0    0  353]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.95      0.99      0.97      4241\n",
      "  2_colonies       0.83      0.84      0.84      1596\n",
      "  3_colonies       0.74      0.74      0.74      1139\n",
      "  4_colonies       0.61      0.57      0.59       568\n",
      "  5_colonies       0.49      0.28      0.36       288\n",
      "  6_colonies       0.72      0.69      0.71       304\n",
      "     outlier       0.98      0.91      0.94       388\n",
      "\n",
      "    accuracy                           0.86      8524\n",
      "   macro avg       0.76      0.72      0.73      8524\n",
      "weighted avg       0.85      0.86      0.86      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('balanced_classes.hdf5')\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4243   36    3    0    0    0    3]\n",
      " [ 129 1443   59    1    0    0    0]\n",
      " [  23  163  845   55    1    2    0]\n",
      " [  12   10  164  316   34   14    0]\n",
      " [   7    2   18  116   88   55    0]\n",
      " [   5    2    4   25   56  209    0]\n",
      " [  23    2    0    0    0    1  352]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.96      0.99      0.97      4285\n",
      "  2_colonies       0.87      0.88      0.88      1632\n",
      "  3_colonies       0.77      0.78      0.77      1089\n",
      "  4_colonies       0.62      0.57      0.59       550\n",
      "  5_colonies       0.49      0.31      0.38       286\n",
      "  6_colonies       0.74      0.69      0.72       301\n",
      "     outlier       0.99      0.93      0.96       378\n",
      "\n",
      "    accuracy                           0.88      8521\n",
      "   macro avg       0.78      0.74      0.75      8521\n",
      "weighted avg       0.87      0.88      0.88      8521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('balanced_classes.hdf5')\n",
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.9240 - acc: 0.6460 - val_loss: 0.8217 - val_acc: 0.7030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x193ba8cf0b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1, \n",
    "                    steps_per_epoch=1000, \n",
    "                    epochs=1, \n",
    "                    validation_data=validation_generator,\n",
    "                   validation_steps=300,\n",
    "                   class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2740 1107  328   27    0   14   25]\n",
      " [ 221  446  550   94   13  257   15]\n",
      " [ 760   41   21    3    2   45  267]\n",
      " [ 552   15    0    0    0    0    1]\n",
      " [ 277   10    0    0    0    0    1]\n",
      " [ 290   13    0    0    0    0    1]\n",
      " [ 378   10    0    0    0    0    0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1_colony       0.53      0.65      0.58      4241\n",
      "  2_colonies       0.27      0.28      0.28      1596\n",
      "  3_colonies       0.02      0.02      0.02      1139\n",
      "  4_colonies       0.00      0.00      0.00       568\n",
      "  5_colonies       0.00      0.00      0.00       288\n",
      "  6_colonies       0.00      0.00      0.00       304\n",
      "     outlier       0.00      0.00      0.00       388\n",
      "\n",
      "    accuracy                           0.38      8524\n",
      "   macro avg       0.12      0.13      0.13      8524\n",
      "weighted avg       0.32      0.38      0.34      8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23398 images belonging to 8 classes.\n",
      "Found 10025 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_generator = datagen.flow_from_directory(full_training_directory, \n",
    "                                              target_size=(128, 128), \n",
    "                                              color_mode=\"grayscale\", \n",
    "                                              batch_size=batch_size)\n",
    "validation_generator = datagen.flow_from_directory(full_validation_directory,\n",
    "                                                   target_size=(128, 128), \n",
    "                                                   color_mode='grayscale',\n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=False)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "num_test_samples = 10025\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5,5), activation='relu', input_shape=(128,128,1)))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(50, (5,5), activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.9))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(100, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(200, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu')) # Added Relu, maybe remove\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01,\n",
    "                          momentum=0.9,\n",
    "                          decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acsch\\Anaconda3\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 111s 222ms/step - loss: 1.2661 - acc: 0.5531 - val_loss: 1.0412 - val_acc: 0.6050\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 1.0078 - acc: 0.6213 - val_loss: 0.9206 - val_acc: 0.6505\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.8690 - acc: 0.6665 - val_loss: 0.7766 - val_acc: 0.6980\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.7651 - acc: 0.7069 - val_loss: 0.7547 - val_acc: 0.7298\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.6882 - acc: 0.7364 - val_loss: 0.5943 - val_acc: 0.7775\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.6436 - acc: 0.7538 - val_loss: 0.5828 - val_acc: 0.7796\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.6116 - acc: 0.7665 - val_loss: 0.5511 - val_acc: 0.7884\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.5757 - acc: 0.7828 - val_loss: 0.5879 - val_acc: 0.7811\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.5471 - acc: 0.7908 - val_loss: 0.5357 - val_acc: 0.7917\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.5286 - acc: 0.7978 - val_loss: 0.4953 - val_acc: 0.8106\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.5184 - acc: 0.8015 - val_loss: 0.5154 - val_acc: 0.8006\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.5012 - acc: 0.8088 - val_loss: 0.4664 - val_acc: 0.8131\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4854 - acc: 0.8143 - val_loss: 0.4502 - val_acc: 0.8331\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4790 - acc: 0.8167 - val_loss: 0.4612 - val_acc: 0.8221\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4742 - acc: 0.8204 - val_loss: 0.4500 - val_acc: 0.8343\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4618 - acc: 0.8229 - val_loss: 0.4324 - val_acc: 0.8426\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4464 - acc: 0.8287 - val_loss: 0.4340 - val_acc: 0.8357\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4451 - acc: 0.8303 - val_loss: 0.4169 - val_acc: 0.8446\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4419 - acc: 0.8322 - val_loss: 0.4291 - val_acc: 0.8366\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.4331 - acc: 0.8330 - val_loss: 0.5224 - val_acc: 0.8034\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4227 - acc: 0.8377 - val_loss: 0.3904 - val_acc: 0.8543\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4184 - acc: 0.8396 - val_loss: 0.3998 - val_acc: 0.8526\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4140 - acc: 0.8414 - val_loss: 0.3926 - val_acc: 0.8551\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4080 - acc: 0.8436 - val_loss: 0.3913 - val_acc: 0.8577\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.4038 - acc: 0.8470 - val_loss: 0.3766 - val_acc: 0.8584\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3987 - acc: 0.8463 - val_loss: 0.3859 - val_acc: 0.8548\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.3976 - acc: 0.8478 - val_loss: 0.3780 - val_acc: 0.8600\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3982 - acc: 0.8479 - val_loss: 0.3707 - val_acc: 0.8625\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3795 - acc: 0.8546 - val_loss: 0.3669 - val_acc: 0.8650\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3873 - acc: 0.8533 - val_loss: 0.3709 - val_acc: 0.8620\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3795 - acc: 0.8563 - val_loss: 0.3505 - val_acc: 0.8689\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3807 - acc: 0.8546 - val_loss: 0.3770 - val_acc: 0.8554\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3722 - acc: 0.8595 - val_loss: 0.3588 - val_acc: 0.8647\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.3723 - acc: 0.8573 - val_loss: 0.3392 - val_acc: 0.8740\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3697 - acc: 0.8586 - val_loss: 0.3543 - val_acc: 0.8727\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.3668 - acc: 0.8583 - val_loss: 0.3470 - val_acc: 0.8697\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3616 - acc: 0.8627 - val_loss: 0.3456 - val_acc: 0.8682\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3606 - acc: 0.8614 - val_loss: 0.3468 - val_acc: 0.8737\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3633 - acc: 0.8621 - val_loss: 0.3388 - val_acc: 0.8753\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3579 - acc: 0.8609 - val_loss: 0.3386 - val_acc: 0.8768\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3524 - acc: 0.8657 - val_loss: 0.3975 - val_acc: 0.8515\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3480 - acc: 0.8668 - val_loss: 0.3277 - val_acc: 0.8759\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3510 - acc: 0.8676 - val_loss: 0.3399 - val_acc: 0.8747\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3524 - acc: 0.8669 - val_loss: 0.3296 - val_acc: 0.8796\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3426 - acc: 0.8675 - val_loss: 0.3320 - val_acc: 0.8765\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3430 - acc: 0.8690 - val_loss: 0.3421 - val_acc: 0.8715\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3398 - acc: 0.8710 - val_loss: 0.3486 - val_acc: 0.8681\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3444 - acc: 0.8679 - val_loss: 0.3328 - val_acc: 0.8751\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.3427 - acc: 0.8695 - val_loss: 0.3272 - val_acc: 0.8781\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3360 - acc: 0.8694 - val_loss: 0.3306 - val_acc: 0.8775\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3336 - acc: 0.8720 - val_loss: 0.3235 - val_acc: 0.8787\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3329 - acc: 0.8729 - val_loss: 0.3298 - val_acc: 0.8776\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.3346 - acc: 0.8713 - val_loss: 0.3283 - val_acc: 0.8776\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3291 - acc: 0.8722 - val_loss: 0.3247 - val_acc: 0.8769\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3291 - acc: 0.8742 - val_loss: 0.3266 - val_acc: 0.8759\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3313 - acc: 0.8731 - val_loss: 0.3165 - val_acc: 0.8821\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3246 - acc: 0.8772 - val_loss: 0.3284 - val_acc: 0.8787\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3272 - acc: 0.8764 - val_loss: 0.3125 - val_acc: 0.8860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3241 - acc: 0.8743 - val_loss: 0.3178 - val_acc: 0.8794\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3249 - acc: 0.8762 - val_loss: 0.3201 - val_acc: 0.8801\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3185 - acc: 0.8777 - val_loss: 0.3208 - val_acc: 0.8818\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3238 - acc: 0.8760 - val_loss: 0.3137 - val_acc: 0.8832\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.3158 - acc: 0.8785 - val_loss: 0.3207 - val_acc: 0.8803\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.3156 - acc: 0.8787 - val_loss: 0.3153 - val_acc: 0.8805\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3204 - acc: 0.8760 - val_loss: 0.3125 - val_acc: 0.8831\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3138 - acc: 0.8787 - val_loss: 0.3131 - val_acc: 0.8841\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3152 - acc: 0.8793 - val_loss: 0.3086 - val_acc: 0.8872\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.3156 - acc: 0.8790 - val_loss: 0.3079 - val_acc: 0.8848\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3121 - acc: 0.8816 - val_loss: 0.3178 - val_acc: 0.8817\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3109 - acc: 0.8800 - val_loss: 0.3123 - val_acc: 0.8830\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3105 - acc: 0.8805 - val_loss: 0.3134 - val_acc: 0.8859\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3077 - acc: 0.8841 - val_loss: 0.3044 - val_acc: 0.8877\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3079 - acc: 0.8812 - val_loss: 0.3109 - val_acc: 0.8862\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3070 - acc: 0.8806 - val_loss: 0.3076 - val_acc: 0.8884\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2984 - acc: 0.8857 - val_loss: 0.3132 - val_acc: 0.8858\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3078 - acc: 0.8822 - val_loss: 0.3009 - val_acc: 0.8887\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3051 - acc: 0.8823 - val_loss: 0.3043 - val_acc: 0.8895\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3037 - acc: 0.8846 - val_loss: 0.3091 - val_acc: 0.8887\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3034 - acc: 0.8831 - val_loss: 0.3006 - val_acc: 0.8876\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.3018 - acc: 0.8840 - val_loss: 0.3071 - val_acc: 0.8851\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2924 - acc: 0.8888 - val_loss: 0.3077 - val_acc: 0.8860\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2985 - acc: 0.8857 - val_loss: 0.2923 - val_acc: 0.8919\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2958 - acc: 0.8872 - val_loss: 0.2998 - val_acc: 0.8882\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2971 - acc: 0.8850 - val_loss: 0.3033 - val_acc: 0.8883\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2995 - acc: 0.8844 - val_loss: 0.3055 - val_acc: 0.8854\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2939 - acc: 0.8879 - val_loss: 0.2990 - val_acc: 0.8876\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2973 - acc: 0.8853 - val_loss: 0.2997 - val_acc: 0.8890\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2943 - acc: 0.8865 - val_loss: 0.3089 - val_acc: 0.8846\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2992 - acc: 0.8862 - val_loss: 0.2984 - val_acc: 0.8914\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2928 - acc: 0.8887 - val_loss: 0.2978 - val_acc: 0.8904\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2927 - acc: 0.8869 - val_loss: 0.2984 - val_acc: 0.8887\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2913 - acc: 0.8894 - val_loss: 0.2938 - val_acc: 0.8932\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2963 - acc: 0.8873 - val_loss: 0.2999 - val_acc: 0.8875\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2911 - acc: 0.8882 - val_loss: 0.3021 - val_acc: 0.8862\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.2922 - acc: 0.8877 - val_loss: 0.2939 - val_acc: 0.8916\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2931 - acc: 0.8884 - val_loss: 0.3012 - val_acc: 0.8890\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2901 - acc: 0.8881 - val_loss: 0.2902 - val_acc: 0.8933\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2909 - acc: 0.8877 - val_loss: 0.2955 - val_acc: 0.8898\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2832 - acc: 0.8914 - val_loss: 0.2998 - val_acc: 0.8919\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2868 - acc: 0.8899 - val_loss: 0.3075 - val_acc: 0.8843\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "balanced_history = model.fit_generator(train_generator,\n",
    "                                       verbose=1, \n",
    "                                       steps_per_epoch=500, \n",
    "                                       epochs=100, \n",
    "                                       validation_data=validation_generator,\n",
    "                                      validation_steps=num_test_samples // batch_size+1,\n",
    "                                      class_weight=class_weights)\n",
    "model.save('balanced_gray_classes.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 439    0    0    0    0    0    0    0]\n",
      " [   3 4981   75    4    1    0    0   10]\n",
      " [   1  150 1698   54    2    0    0    3]\n",
      " [   1   36  176  824   47    4    1    0]\n",
      " [   0   16    6  170  294   53   11    0]\n",
      " [   0    3    2   19   93  122   46    1]\n",
      " [   0   11    1    7   19   82  179    2]\n",
      " [   1   16    2    1    0    0    0  358]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  0_colonies       0.99      1.00      0.99       439\n",
      "    1_colony       0.96      0.98      0.97      5074\n",
      "  2_colonies       0.87      0.89      0.88      1908\n",
      "  3_colonies       0.76      0.76      0.76      1089\n",
      "  4_colonies       0.64      0.53      0.58       550\n",
      "  5_colonies       0.47      0.43      0.45       286\n",
      "  6_colonies       0.76      0.59      0.67       301\n",
      "     outlier       0.96      0.95      0.95       378\n",
      "\n",
      "    accuracy                           0.89     10025\n",
      "   macro avg       0.80      0.77      0.78     10025\n",
      "weighted avg       0.88      0.89      0.88     10025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.load_model('balanced_gray_classes.hdf5')\n",
    "validation_generator.reset()\n",
    "Y_pred = model2.predict_generator(validation_generator, num_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0_colonies','1_colony', '2_colonies', '3_colonies', '4_colonies', '5_colonies', '6_colonies', 'outlier']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8799199674905183]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8091256e-15, 9.7918092e-18, 4.0638271e-10, ..., 3.7677091e-01,\n",
       "        6.7156717e-02, 7.4900477e-18],\n",
       "       [2.8744179e-12, 4.4079595e-14, 1.3031728e-05, ..., 5.1736284e-02,\n",
       "        2.4789143e-03, 2.2783513e-14],\n",
       "       [7.0208116e-05, 1.5387968e-04, 3.9175007e-02, ..., 7.6512583e-02,\n",
       "        2.2225235e-02, 1.0948159e-05],\n",
       "       ...,\n",
       "       [8.7583613e-10, 4.8992523e-16, 2.5101923e-07, ..., 2.5697449e-01,\n",
       "        6.1039466e-02, 3.1508889e-11],\n",
       "       [1.7918350e-17, 3.5399584e-23, 4.2578211e-12, ..., 5.0740635e-01,\n",
       "        8.9521043e-02, 9.5164997e-20],\n",
       "       [2.8162518e-18, 7.4315928e-25, 2.4202788e-19, ..., 1.2741689e-01,\n",
       "        8.6996293e-01, 1.4945137e-18]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
